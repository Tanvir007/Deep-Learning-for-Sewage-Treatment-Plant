{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qAJeJ3Ygk0AqFs4mbdkXfm664G8nVgDA",
      "authorship_tag": "ABX9TyMgTw5kXFDLmSAi06PwZDmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanvir007/Deep-Learning-for-Sewage-Treatment-Plant/blob/main/Performance_Analysis_DTP_IWFM_BUET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V6I3SqiBLHsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n"
      ],
      "metadata": {
        "id": "EcwIfOG8FjuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from CSV file\n",
        "data = pd.read_csv('/content/drive/MyDrive/BUET Thesis/DSTP.csv')"
      ],
      "metadata": {
        "id": "QSHUirkefDjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ncpkv2IdfVPK",
        "outputId": "fba48267-7733-45d6-cbf1-287904ba6943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date  InQuantitySLSMLD  EfDischargetoGojariaMLD  InpH  EfpH  InCOD  \\\n",
              "0  1/10/2022            260.01                   257.37  7.52  7.46    238   \n",
              "1  2/10/2022            266.43                   265.45  7.25  7.37    298   \n",
              "2  3/10/2022            290.04                   285.96  7.24  7.26    296   \n",
              "3  4/10/2022            203.68                   201.39  7.34  7.42    153   \n",
              "4  5/10/2022            285.10                   276.07  7.51  7.38    287   \n",
              "\n",
              "   EfCOD  InBOD  EfBOD  InAmmonia  EfAmmonia  InSS  EfSS  InPhosphate  \\\n",
              "0      8   87.1    1.4       23.4       0.20   182     2         3.52   \n",
              "1      4   81.1    1.7       22.5       0.21   218     1         2.98   \n",
              "2      4   68.7    2.3       20.2       0.18   158     1         3.51   \n",
              "3      5   86.3    1.3       20.8       0.19   122     2         3.16   \n",
              "4      7   76.9    1.9       20.2       0.20   146     2         3.08   \n",
              "\n",
              "   EfPhosphate  InFecalColiform  EfFecalColiform  \n",
              "0         1.31             4600               49  \n",
              "1         1.43             4300               27  \n",
              "2         1.75             7900               34  \n",
              "3         1.62             9400               43  \n",
              "4         1.27             6300               33  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5b649ce-3567-4f9e-a401-53d0db17d7ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>InQuantitySLSMLD</th>\n",
              "      <th>EfDischargetoGojariaMLD</th>\n",
              "      <th>InpH</th>\n",
              "      <th>EfpH</th>\n",
              "      <th>InCOD</th>\n",
              "      <th>EfCOD</th>\n",
              "      <th>InBOD</th>\n",
              "      <th>EfBOD</th>\n",
              "      <th>InAmmonia</th>\n",
              "      <th>EfAmmonia</th>\n",
              "      <th>InSS</th>\n",
              "      <th>EfSS</th>\n",
              "      <th>InPhosphate</th>\n",
              "      <th>EfPhosphate</th>\n",
              "      <th>InFecalColiform</th>\n",
              "      <th>EfFecalColiform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/10/2022</td>\n",
              "      <td>260.01</td>\n",
              "      <td>257.37</td>\n",
              "      <td>7.52</td>\n",
              "      <td>7.46</td>\n",
              "      <td>238</td>\n",
              "      <td>8</td>\n",
              "      <td>87.1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>23.4</td>\n",
              "      <td>0.20</td>\n",
              "      <td>182</td>\n",
              "      <td>2</td>\n",
              "      <td>3.52</td>\n",
              "      <td>1.31</td>\n",
              "      <td>4600</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2/10/2022</td>\n",
              "      <td>266.43</td>\n",
              "      <td>265.45</td>\n",
              "      <td>7.25</td>\n",
              "      <td>7.37</td>\n",
              "      <td>298</td>\n",
              "      <td>4</td>\n",
              "      <td>81.1</td>\n",
              "      <td>1.7</td>\n",
              "      <td>22.5</td>\n",
              "      <td>0.21</td>\n",
              "      <td>218</td>\n",
              "      <td>1</td>\n",
              "      <td>2.98</td>\n",
              "      <td>1.43</td>\n",
              "      <td>4300</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3/10/2022</td>\n",
              "      <td>290.04</td>\n",
              "      <td>285.96</td>\n",
              "      <td>7.24</td>\n",
              "      <td>7.26</td>\n",
              "      <td>296</td>\n",
              "      <td>4</td>\n",
              "      <td>68.7</td>\n",
              "      <td>2.3</td>\n",
              "      <td>20.2</td>\n",
              "      <td>0.18</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>3.51</td>\n",
              "      <td>1.75</td>\n",
              "      <td>7900</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4/10/2022</td>\n",
              "      <td>203.68</td>\n",
              "      <td>201.39</td>\n",
              "      <td>7.34</td>\n",
              "      <td>7.42</td>\n",
              "      <td>153</td>\n",
              "      <td>5</td>\n",
              "      <td>86.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>20.8</td>\n",
              "      <td>0.19</td>\n",
              "      <td>122</td>\n",
              "      <td>2</td>\n",
              "      <td>3.16</td>\n",
              "      <td>1.62</td>\n",
              "      <td>9400</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5/10/2022</td>\n",
              "      <td>285.10</td>\n",
              "      <td>276.07</td>\n",
              "      <td>7.51</td>\n",
              "      <td>7.38</td>\n",
              "      <td>287</td>\n",
              "      <td>7</td>\n",
              "      <td>76.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>20.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>146</td>\n",
              "      <td>2</td>\n",
              "      <td>3.08</td>\n",
              "      <td>1.27</td>\n",
              "      <td>6300</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5b649ce-3567-4f9e-a401-53d0db17d7ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c5b649ce-3567-4f9e-a401-53d0db17d7ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c5b649ce-3567-4f9e-a401-53d0db17d7ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a91fcb4f-e8da-4774-a466-d460d5b9c8b8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a91fcb4f-e8da-4774-a466-d460d5b9c8b8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a91fcb4f-e8da-4774-a466-d460d5b9c8b8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target (y)\n",
        "X = data[['InQuantitySLSMLD','InpH', 'InCOD', 'InBOD', 'InAmmonia', 'InSS', 'InPhosphate', 'InFecalColiform','EfpH','EfCOD','EfBOD','EfAmmonia','EfSS','EfPhosphate','EfFecalColiform'\t\t]]  # Exclude the date column\n",
        "y = data[\"EfDischargetoGojariaMLD\"]\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = np.array(y).reshape(-1, 1)\n",
        "y = scaler.fit_transform(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "cLvsz0kMJE-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define evaluation metrics lists\n",
        "rmse_list, mae_list, r2_list, mape_list = [], [], [], []"
      ],
      "metadata": {
        "id": "6m-a1WxeKeN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Artificial Neural Network (ANN) Model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "ann_preds = model.predict(X_test)\n",
        "ann_preds = scaler.inverse_transform(ann_preds)\n",
        "rmse_ann = np.sqrt(mean_squared_error(scaler.inverse_transform(y_test), ann_preds))\n",
        "mae_ann = mean_absolute_error(scaler.inverse_transform(y_test), ann_preds)\n",
        "r2_ann = r2_score(scaler.inverse_transform(y_test), ann_preds)\n",
        "mape_ann = mean_absolute_percentage_error(scaler.inverse_transform(y_test), ann_preds)\n",
        "rmse_list.append(rmse_ann)\n",
        "mae_list.append(mae_ann)\n",
        "r2_list.append(r2_ann)\n",
        "mape_list.append(mape_ann)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVwh5TA_LGed",
        "outputId": "7dd13abf-f544-4de6-d099-b88466b42943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0816\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0350\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0392\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0297\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0252\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0228\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0183\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0164\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0121\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0107\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0093\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0084\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0075\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0068\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0061\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0050\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0046\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0042\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0038\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0035\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0033\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0030\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0028\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0028\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0025\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 9.6167e-04\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 9.1316e-04\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 8.7566e-04\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.1968e-04\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 7.7949e-04\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 7.7329e-04\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 7.2100e-04\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 6.8490e-04\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 6.5759e-04\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 6.3101e-04\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 6.2732e-04\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 5.8546e-04\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 5.6511e-04\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 5.4655e-04\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 5.2760e-04\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 5.2202e-04\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 5.1937e-04\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 5.0617e-04\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 4.9634e-04\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 4.9643e-04\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 4.6053e-04\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 4.5747e-04\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 4.3532e-04\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 4.2322e-04\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 4.1974e-04\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 4.3196e-04\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 4.2315e-04\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 4.2546e-04\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 4.2385e-04\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.8840e-04\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 3.7203e-04\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.7035e-04\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.5929e-04\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.5753e-04\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 3.5516e-04\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.6333e-04\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.5798e-04\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.3928e-04\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.3227e-04\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.3805e-04\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.3777e-04\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 3.2098e-04\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 3.2167e-04\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 3.1599e-04\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.1247e-04\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.0772e-04\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.0345e-04\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.0682e-04\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.0156e-04\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.0386e-04\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 3.0756e-04\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 2.9762e-04\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 2.9421e-04\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 2.8562e-04\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 2.8296e-04\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 2.8530e-04\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 2.8350e-04\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 2.8213e-04\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 2.7924e-04\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 2.8811e-04\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 2.8918e-04\n",
            "3/3 [==============================] - 0s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recurrent Neural Network (RNN) Model\n",
        "X_train_rnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_rnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "model_rnn.add(Dense(1))\n",
        "model_rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_rnn.fit(X_train_rnn, y_train, epochs=100, batch_size=32)\n",
        "rnn_preds = model_rnn.predict(X_test_rnn)\n",
        "rnn_preds = scaler.inverse_transform(rnn_preds)\n",
        "rmse_rnn = np.sqrt(mean_squared_error(scaler.inverse_transform(y_test), rnn_preds))\n",
        "mae_rnn = mean_absolute_error(scaler.inverse_transform(y_test), rnn_preds)\n",
        "r2_rnn = r2_score(scaler.inverse_transform(y_test), rnn_preds)\n",
        "mape_rnn = mean_absolute_percentage_error(scaler.inverse_transform(y_test), rnn_preds)\n",
        "rmse_list.append(rmse_rnn)\n",
        "mae_list.append(mae_rnn)\n",
        "r2_list.append(r2_rnn)\n",
        "mape_list.append(mape_rnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24L7UlUlLNtT",
        "outputId": "efd873c9-9729-4d38-c3aa-957491536bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 9ms/step - loss: 0.2001\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1270\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0610\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0272\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0300\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0223\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0246\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0227\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0218\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0223\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0218\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0219\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0216\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0216\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0217\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0218\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0216\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0213\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0213\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0214\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0213\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0213\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0212\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0210\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0210\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0210\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0209\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0209\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0208\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0208\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0208\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0208\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0208\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0208\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0207\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0208\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0206\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0205\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0204\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0206\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0201\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0204\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0204\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0201\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0202\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0208\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0198\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0196\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0195\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0193\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0191\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0188\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0186\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0185\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0179\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0171\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0166\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0156\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0149\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0142\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0153\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0137\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0116\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0126\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0112\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0080\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0071\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0067\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0069\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0068\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0061\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0057\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0051\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0050\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0049\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0043\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0044\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0040\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0040\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0040\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0036\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0038\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0044\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0045\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0036\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0036\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0036\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0028\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0026\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0019\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0021\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0023\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "3/3 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Long Short-Term Memory (LSTM) Model\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "model_lstm.add(Dense(1))\n",
        "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_lstm.fit(X_train_rnn, y_train, epochs=100, batch_size=32)\n",
        "lstm_preds = model_lstm.predict(X_test_rnn)\n",
        "lstm_preds = scaler.inverse_transform(lstm_preds)\n",
        "rmse_lstm = np.sqrt(mean_squared_error(scaler.inverse_transform(y_test), lstm_preds))\n",
        "mae_lstm = mean_absolute_error(scaler.inverse_transform(y_test), lstm_preds)\n",
        "r2_lstm = r2_score(scaler.inverse_transform(y_test), lstm_preds)\n",
        "mape_lstm = mean_absolute_percentage_error(scaler.inverse_transform(y_test), lstm_preds)\n",
        "rmse_list.append(rmse_lstm)\n",
        "mae_list.append(mae_lstm)\n",
        "r2_list.append(r2_lstm)\n",
        "mape_list.append(mape_lstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf97NSUILXa5",
        "outputId": "d26e0e17-d9d7-4248-fe7c-fbee3a89c06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 5ms/step - loss: 0.2058\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1461\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0862\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0296\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0352\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0230\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0251\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0227\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0220\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0216\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0212\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0215\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0212\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0211\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0209\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0209\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0208\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0209\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0216\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0208\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0207\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0207\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0205\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0206\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0204\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0204\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0207\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0203\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0201\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0200\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0198\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0199\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0196\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0193\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0193\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0190\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0189\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0182\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0181\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0181\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0168\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0158\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0150\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0140\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0121\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0109\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0098\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0080\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0087\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0092\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0083\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0069\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0048\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0042\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0038\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0034\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0032\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0032\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0028\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0027\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0025\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0022\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0022\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0021\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0017\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bi-Directional LSTM (BiLSTM) Model\n",
        "model_bilstm = Sequential()\n",
        "model_bilstm.add(Bidirectional(LSTM(64, activation='relu'), input_shape=(X_train.shape[1], 1)))\n",
        "model_bilstm.add(Dense(1))\n",
        "model_bilstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_bilstm.fit(X_train_rnn, y_train, epochs=100, batch_size=32)\n",
        "bilstm_preds = model_bilstm.predict(X_test_rnn)\n",
        "bilstm_preds = scaler.inverse_transform(bilstm_preds)\n",
        "rmse_bilstm = np.sqrt(mean_squared_error(scaler.inverse_transform(y_test), bilstm_preds))\n",
        "mae_bilstm = mean_absolute_error(scaler.inverse_transform(y_test), bilstm_preds)\n",
        "r2_bilstm = r2_score(scaler.inverse_transform(y_test), bilstm_preds)\n",
        "mape_bilstm = mean_absolute_percentage_error(scaler.inverse_transform(y_test), bilstm_preds)\n",
        "rmse_list.append(rmse_bilstm)\n",
        "mae_list.append(mae_bilstm)\n",
        "r2_list.append(r2_bilstm)\n",
        "mape_list.append(mape_bilstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ELSDCx6ZLdxr",
        "outputId": "e4de9ca8-2dd0-49de-f7c5-b4669068281c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 2s 9ms/step - loss: 127929.9297\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 127842.1641\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 127693.9922\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 127332.9922\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 125716.4844\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 97619.0781\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 28286.4551\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 34875.6172\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21772.2598\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 15141.1641\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 16027.9473\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14269.4893\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12542.9492\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10998.9717\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10450.5889\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9140.7549\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8425.3682\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7614.0542\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5978.1479\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5200.4531\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4598.6152\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4102.1748\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3070.0300\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3227.2673\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2882.2788\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2942.6013\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2897.0811\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3146.7080\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3610.9287\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2992.0684\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2714.1465\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2550.8979\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2744.1360\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2679.2776\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2893.0652\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2890.0422\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2983.0547\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2586.0950\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2951.0906\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2957.2107\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3184.0537\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3471.1824\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2779.2366\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3020.3018\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2906.5771\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2756.7336\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2587.9878\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2418.5276\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2319.5830\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2234.7556\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2178.0554\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2096.7507\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2158.1118\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2087.4934\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2211.9595\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2504.0254\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2582.6152\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1891.0518\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1444.7683\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1405.7266\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1269.4626\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1287.5547\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1225.7731\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1253.1202\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1321.5533\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 949.1791\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 908.5720\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 826.9670\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 805.7863\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 774.0070\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 716.0743\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 752.2720\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 684.4794\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 677.5710\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 710.6926\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 669.8539\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 611.4289\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 611.1407\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 641.5500\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 803.4219\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 726.7983\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 694.7280\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 659.4260\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 607.8949\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 549.5923\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 518.2993\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 571.8206\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 606.1089\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 770.0760\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 640.4901\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 572.2723\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 548.5400\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 646.0352\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 554.1263\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 509.2395\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 469.5726\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 493.4076\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 451.1729\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 483.2465\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 521.2600\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-a9eaa9462375>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_bilstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_bilstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbilstm_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_bilstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_bilstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mbilstm_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbilstm_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mrmse_bilstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbilstm_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test_bilstm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the evaluation metrics\n",
        "for i, model_name in enumerate([\"ANN\", \"RNN\", \"LSTM\", \"BiLSTM\"]):\n",
        "    print(f\"{model_name} RMSE: {rmse_list[i]}\")\n",
        "    print(f\"{model_name} MAE: {mae_list[i]}\")\n",
        "    print(f\"{model_name} R2: {r2_list[i]}\")\n",
        "    print(f\"{model_name} MAPE: {mape_list[i]}\")\n",
        "\n",
        "# Now you have lists of RMSE, MAE, R2, and MAPE for each model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrSNbEmYLkJ5",
        "outputId": "6a540529-9fc4-483d-d05d-e780d25255c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN RMSE: 8.998995261704193\n",
            "ANN MAE: 6.218088617092225\n",
            "ANN R2: 0.9690650378076177\n",
            "ANN MAPE: 0.017645136966487184\n",
            "RNN RMSE: 14.762969609251252\n",
            "RNN MAE: 11.158429535656445\n",
            "RNN R2: 0.9167452550413872\n",
            "RNN MAPE: 0.031007594081762804\n",
            "LSTM RMSE: 14.422312507309687\n",
            "LSTM MAE: 8.740071381359565\n",
            "LSTM R2: 0.9205431494536116\n",
            "LSTM MAPE: 0.0237434942464567\n",
            "BiLSTM RMSE: 11.493071434147382\n",
            "BiLSTM MAE: 8.506368750595461\n",
            "BiLSTM R2: 0.9495415674547181\n",
            "BiLSTM MAPE: 0.023842174541942148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_pred_ann)\n",
        "plt.title(\"ANN: Actual vs. Predicted\")\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "rX4LqyY89IN6",
        "outputId": "621ea848-3fa5-4cee-f0da-fd1f0a9c483b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-efef5feda075>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_ann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ANN: Actual vs. Predicted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Actual\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred_ann' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "id": "pFOLdDjTQiR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a7eca7-0f6e-44f4-b0f8-cd54f68df8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install anfis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNvAEhSgzTz1",
        "outputId": "801164a5-1a9b-4a2b-d491-c28e09653a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anfis\n",
            "  Downloading anfis-0.3.1-py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from anfis) (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from anfis) (3.7.1)\n",
            "Collecting scikit-fuzzy (from anfis)\n",
            "  Downloading scikit-fuzzy-0.4.2.tar.gz (993 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m994.0/994.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (2.8.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy->anfis) (1.11.3)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy->anfis) (3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->anfis) (1.16.0)\n",
            "Building wheels for collected packages: scikit-fuzzy\n",
            "  Building wheel for scikit-fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-fuzzy: filename=scikit_fuzzy-0.4.2-py3-none-any.whl size=894079 sha256=a8d8b8a60da4a937a77258a19bd4d0f63d189a3e6709c9376adc2ad39ce639d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/86/1b/dfd97134a2c8313e519bcebd95d3fedc7be7944db022094bc8\n",
            "Successfully built scikit-fuzzy\n",
            "Installing collected packages: scikit-fuzzy, anfis\n",
            "Successfully installed anfis-0.3.1 scikit-fuzzy-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
      ],
      "metadata": {
        "id": "qGOA4aoF0Cmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['InQuantitySLSMLD','InpH', 'InCOD', 'InBOD', 'InAmmonia', 'InSS', 'InPhosphate', 'InFecalColiform','EfpH','EfCOD','EfBOD','EfAmmonia','EfSS','EfPhosphate','EfFecalColiform'\t\t]]  # Exclude the date column\n",
        "y = data[\"EfDischargetoGojariaMLD\"]"
      ],
      "metadata": {
        "id": "vSnrk5Dj0X8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features (if needed)\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training (70%) and testing (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "CHXk4KDe0goH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anfis\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONIV_NLu0pBW",
        "outputId": "ecf0afe5-ae76-457a-af4a-e52ac75f9551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anfis in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from anfis) (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from anfis) (3.7.1)\n",
            "Requirement already satisfied: scikit-fuzzy in /usr/local/lib/python3.10/dist-packages (from anfis) (0.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (2.8.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy->anfis) (1.11.3)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy->anfis) (3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->anfis) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list anfis\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqy7QsUU0seI",
        "outputId": "55ecb8a8-3ac1-45f3-c9e2-b31ed942f835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "aiohttp                          3.8.6\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.13\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "anfis                            0.3.1\n",
            "anyio                            3.7.1\n",
            "appdirs                          1.4.4\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array-record                     0.4.1\n",
            "arviz                            0.15.1\n",
            "astropy                          5.3.4\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.0\n",
            "attrs                            23.1.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.13.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.11.2\n",
            "bidict                           0.22.1\n",
            "bigframes                        0.8.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.2.2\n",
            "bqplot                           0.12.42\n",
            "branca                           0.6.0\n",
            "build                            1.0.3\n",
            "CacheControl                     0.13.1\n",
            "cachetools                       5.3.1\n",
            "catalogue                        2.0.10\n",
            "certifi                          2023.7.22\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.0\n",
            "chex                             0.1.7\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.7\n",
            "cmdstanpy                        1.2.0\n",
            "colorcet                         3.0.1\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.3\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.1.1\n",
            "cryptography                     41.0.4\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda11x                     11.0.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.2\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.4\n",
            "dask                             2023.8.1\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.1.1\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "diskcache                        5.6.3\n",
            "distributed                      2023.8.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docutils                         0.18.1\n",
            "dopamine-rl                      4.0.6\n",
            "duckdb                           0.8.1\n",
            "earthengine-api                  0.1.374\n",
            "easydict                         1.10\n",
            "ecos                             2.0.12\n",
            "editdistance                     0.6.2\n",
            "eerepr                           0.0.4\n",
            "en-core-web-sm                   3.6.0\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.5.1\n",
            "etuples                          0.3.9\n",
            "exceptiongroup                   1.1.3\n",
            "fastai                           2.7.13\n",
            "fastcore                         1.5.29\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.18.1\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.12.4\n",
            "fiona                            1.9.5\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      23.5.26\n",
            "flax                             0.7.4\n",
            "folium                           0.14.0\n",
            "fonttools                        4.43.1\n",
            "frozendict                       2.3.8\n",
            "frozenlist                       1.4.0\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.4.0\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.4.3\n",
            "gdown                            4.6.6\n",
            "geemap                           0.28.2\n",
            "gensim                           4.3.2\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-api-core                  2.11.1\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.17.3\n",
            "google-auth-httplib2             0.1.1\n",
            "google-auth-oauthlib             1.0.0\n",
            "google-cloud-bigquery            3.10.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.22.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.3\n",
            "google-cloud-iam                 2.12.2\n",
            "google-cloud-language            2.9.1\n",
            "google-cloud-resource-manager    1.10.4\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.6.0\n",
            "googleapis-common-protos         1.61.0\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.1\n",
            "greenlet                         3.0.0\n",
            "grpc-google-iam-v1               0.12.6\n",
            "grpcio                           1.59.0\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          3.4.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.2.0\n",
            "h5py                             3.9.0\n",
            "holidays                         0.35\n",
            "holoviews                        1.17.1\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   6.2.0\n",
            "idna                             3.4\n",
            "imageio                          2.31.5\n",
            "imageio-ffmpeg                   0.4.9\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "importlib-metadata               6.8.0\n",
            "importlib-resources              6.1.0\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "install                          1.3.5\n",
            "intel-openmp                     2023.2.0\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.17.4\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.1.2\n",
            "jax                              0.4.16\n",
            "jaxlib                           0.4.16+cuda11.cudnn86\n",
            "jeepney                          0.7.1\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.2\n",
            "joblib                           1.3.2\n",
            "jsonpickle                       3.0.2\n",
            "jsonschema                       4.19.1\n",
            "jsonschema-specifications        2023.7.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.4.0\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab-pygments              0.2.2\n",
            "jupyterlab-widgets               3.0.9\n",
            "kaggle                           1.5.16\n",
            "keras                            2.13.1\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langcodes                        3.3.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.3\n",
            "libclang                         16.0.6\n",
            "librosa                          0.10.1\n",
            "lida                             0.0.10\n",
            "lightgbm                         4.0.0\n",
            "linkify-it-py                    2.0.2\n",
            "llmx                             0.0.15a0\n",
            "llvmlite                         0.39.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.3\n",
            "malloy                           2023.1056\n",
            "Markdown                         3.5\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.3\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.6\n",
            "matplotlib-venn                  0.11.9\n",
            "mdit-py-plugins                  0.4.0\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.3.1\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.7\n",
            "multidict                        6.0.4\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.0.0\n",
            "nbclient                         0.8.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.9.2\n",
            "nest-asyncio                     1.5.8\n",
            "networkx                         3.1\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.3\n",
            "numba                            0.56.4\n",
            "numexpr                          2.8.7\n",
            "numpy                            1.23.5\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.8.1.78\n",
            "openpyxl                         3.1.2\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.1.7\n",
            "orbax-checkpoint                 0.4.1\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        23.2\n",
            "pandas                           1.5.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.17.9\n",
            "pandas-stubs                     1.5.3.230304\n",
            "pandocfilters                    1.5.0\n",
            "panel                            1.2.3\n",
            "param                            1.13.0\n",
            "parso                            0.8.3\n",
            "parsy                            2.1\n",
            "partd                            1.4.1\n",
            "pathlib                          1.0.1\n",
            "pathy                            0.10.2\n",
            "patsy                            0.5.3\n",
            "peewee                           3.17.0\n",
            "pexpect                          4.8.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     3.11.0\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.3\n",
            "pluggy                           1.3.0\n",
            "polars                           0.17.3\n",
            "pooch                            1.7.0\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.9.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus-client                0.17.1\n",
            "promise                          2.3\n",
            "prompt-toolkit                   3.0.39\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.22.3\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          9.0.0\n",
            "pyasn1                           0.5.0\n",
            "pyasn1-modules                   0.3.0\n",
            "pycocotools                      2.0.7\n",
            "pycparser                        2.21\n",
            "pyct                             0.5.0\n",
            "pydantic                         1.10.13\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1\n",
            "pygame                           2.5.2\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.7.2\n",
            "pymystem3                        0.2.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        23.2.0\n",
            "pyparsing                        3.1.1\n",
            "pyperclip                        1.8.2\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.0.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.14.2\n",
            "pytest                           7.4.2\n",
            "python-apt                       0.0.0\n",
            "python-box                       7.1.1\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.1\n",
            "python-utils                     3.8.1\n",
            "pytz                             2023.3.post1\n",
            "pyviz_comms                      3.0.0\n",
            "PyWavelets                       1.4.1\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            23.2.1\n",
            "qdldl                            0.1.7.post0\n",
            "qudida                           0.0.4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.30.2\n",
            "regex                            2023.6.3\n",
            "requests                         2.31.0\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.5.0\n",
            "rich                             13.6.0\n",
            "rpds-py                          0.10.6\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "scikit-fuzzy                     0.4.2\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.11.3\n",
            "scooby                           0.7.4\n",
            "scs                              3.2.3\n",
            "seaborn                          0.12.2\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.2\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.2\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       6.4.0\n",
            "sniffio                          1.3.0\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.3.7\n",
            "spacy                            3.6.1\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.7\n",
            "sphinxcontrib-devhelp            1.0.5\n",
            "sphinxcontrib-htmlhelp           2.0.4\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.6\n",
            "sphinxcontrib-serializinghtml    1.1.9\n",
            "SQLAlchemy                       2.0.22\n",
            "sqlglot                          17.16.2\n",
            "sqlparse                         0.4.4\n",
            "srsly                            2.4.8\n",
            "stanio                           0.3.0\n",
            "statsmodels                      0.14.0\n",
            "sympy                            1.12\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.10.0\n",
            "tblib                            2.0.0\n",
            "tenacity                         8.2.3\n",
            "tensorboard                      2.13.0\n",
            "tensorboard-data-server          0.7.1\n",
            "tensorflow                       2.13.0\n",
            "tensorflow-datasets              4.9.3\n",
            "tensorflow-estimator             2.13.0\n",
            "tensorflow-gcs-config            2.13.0\n",
            "tensorflow-hub                   0.15.0\n",
            "tensorflow-io-gcs-filesystem     0.34.0\n",
            "tensorflow-metadata              1.14.0\n",
            "tensorflow-probability           0.20.1\n",
            "tensorstore                      0.1.45\n",
            "termcolor                        2.3.0\n",
            "terminado                        0.17.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.1.12\n",
            "threadpoolctl                    3.2.0\n",
            "tifffile                         2023.9.26\n",
            "tinycss2                         1.2.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.0\n",
            "torch                            2.1.0+cu118\n",
            "torchaudio                       2.1.0+cu118\n",
            "torchdata                        0.7.0\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.16.0\n",
            "torchvision                      0.16.0+cu118\n",
            "tornado                          6.3.2\n",
            "tqdm                             4.66.1\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "triton                           2.1.0\n",
            "tweepy                           4.13.0\n",
            "typer                            0.9.0\n",
            "types-pytz                       2023.3.1.1\n",
            "types-setuptools                 68.2.0.0\n",
            "typing_extensions                4.5.0\n",
            "tzlocal                          5.1\n",
            "uc-micro-py                      1.0.2\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.2\n",
            "wcwidth                          0.2.8\n",
            "webcolors                        1.13\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.6.4\n",
            "Werkzeug                         3.0.0\n",
            "wheel                            0.41.2\n",
            "widgetsnbextension               3.6.6\n",
            "wordcloud                        1.9.2\n",
            "wrapt                            1.15.0\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.6.0\n",
            "xgboost                          2.0.0\n",
            "xlrd                             2.0.1\n",
            "xxhash                           3.4.1\n",
            "xyzservices                      2023.10.0\n",
            "yarl                             1.9.2\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.31\n",
            "zict                             3.0.0\n",
            "zipp                             3.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anfis --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9Jz8zLv1dqR",
        "outputId": "53840a7f-5d9d-46ff-83b9-c15c8c4c585a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anfis in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from anfis) (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from anfis) (3.7.1)\n",
            "Requirement already satisfied: scikit-fuzzy in /usr/local/lib/python3.10/dist-packages (from anfis) (0.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->anfis) (2.8.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy->anfis) (1.11.3)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy->anfis) (3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->anfis) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-fuzzy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF5EXD_q1__b",
        "outputId": "4926ed81-6f4c-4a27-800e-f5a8adf9339b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-fuzzy in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.11.3)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Feed-Forward Neural Network (FFNN) model\n",
        "model_ffnn = MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=1000)\n",
        "model_ffnn.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "DCRgy8013LjF",
        "outputId": "84d725b9-278e-4213-fe8a-8a347a31551d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "y_pred_ffnn = model_ffnn.predict(X_test)"
      ],
      "metadata": {
        "id": "rrCikvzq6UpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_ffnn = np.sqrt(mean_squared_error(y_test, y_pred_ffnn))\n",
        "mae_ffnn = mean_absolute_error(y_test, y_pred_ffnn)\n",
        "r2_ffnn = r2_score(y_test, y_pred_ffnn)"
      ],
      "metadata": {
        "id": "oTDBJJs96XqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mape_ffnn = np.mean(np.abs((y_test - y_pred_ffnn) / y_test)) * 100\n"
      ],
      "metadata": {
        "id": "VDZ6g6ah6cq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FFNN - RMSE:\", rmse_ffnn)\n",
        "print(\"FFNN - MAE:\", mae_ffnn)\n",
        "print(\"FFNN - R2:\", r2_ffnn)\n",
        "print(\"FFNN - MAPE:\", mape_ffnn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZUSMT2X6fjQ",
        "outputId": "a6766f31-4544-47d2-de3d-0d9235fe5bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FFNN - RMSE: 52.827406636007\n",
            "FFNN - MAE: 39.141921297929684\n",
            "FFNN - R2: -0.06605626208901194\n",
            "FFNN - MAPE: 10.484655651912506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_pred_ffnn)\n",
        "plt.title(\"FFNN: Actual vs. Predicted\")\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "3Rsc1IVx6hvq",
        "outputId": "b067b475-2b0b-438b-fe84-29c5147e33fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_pred_ffnn)\n",
        "plt.title(\"ANN: Actual vs. Predicted\")\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "fVMXBoQi67vD",
        "outputId": "75771c6c-4fa5-4e97-f7f5-f7753fee6dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "# Create and train the ANN model\n",
        "ann_model = MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=1000)\n",
        "ann_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "ann_predictions = ann_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "ann_rmse = mean_squared_error(y_test, ann_predictions, squared=False)\n",
        "ann_mae = mean_absolute_error(y_test, ann_predictions)\n",
        "ann_mape = mean_absolute_percentage_error(y_test, ann_predictions)\n",
        "ann_r2 = r2_score(y_test, ann_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvNXoRE58pjA",
        "outputId": "772c71ed-4781-4af7-f322-3d778865190b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import SimpleRNN, LSTM, Dense\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "# Create and train the RNN model (using LSTM as an example)\n",
        "rnn_model = Sequential()\n",
        "rnn_model.add(LSTM(50, activation='relu', input_shape=(timesteps, features)))\n",
        "rnn_model.add(Dense(1))\n",
        "\n",
        "rnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "rnn_model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Make predictions\n",
        "rnn_predictions = rnn_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "rnn_rmse = mean_squared_error(y_test, rnn_predictions, squared=False)\n",
        "rnn_mae = mean_absolute_error(y_test, rnn_predictions)\n",
        "rnn_mape = mean_absolute_percentage_error(y_test, rnn_predictions)\n",
        "rnn_r2 = r2_score(y_test, rnn_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "o2zqqH7v815_",
        "outputId": "91405e6f-2eec-4f61-ad69-e403e496c2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-8d343aa5b92f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create and train the RNN model (using LSTM as an example)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mrnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'timesteps' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data from the provided Excel file\n",
        "file_path = '/mnt/data/DSTP Data.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "6mc0QGIA851K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, r2_score, mean_absolute_error, median_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Create a binary target variable based on a threshold for high/low removal efficiency\n",
        "threshold = data['Removal Efficiency BOD'].median()\n",
        "data['High Removal BOD'] = (data['Removal Efficiency BOD'] >= threshold).astype(int)\n",
        "\n",
        "# Define features and target\n",
        "features = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                 'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                 'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target = data['High Removal BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions = lr_model.predict(X_train)\n",
        "test_predictions = lr_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "# Calculate R scores for training and testing sets (using pseudo-R as logistic regression doesn't directly support R)\n",
        "train_r2 = r2_score(y_train, train_predictions)\n",
        "test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "# Calculate MAE and MdSE for the test set\n",
        "mae_value = mean_absolute_error(y_test, test_predictions)\n",
        "mdse_value = median_absolute_error(y_test, test_predictions)\n",
        "\n",
        "# Results\n",
        "results = {\n",
        "    \"Accuracy (Train)\": train_accuracy,\n",
        "    \"Accuracy (Test)\": test_accuracy,\n",
        "    \"R Score (Train)\": train_r2,\n",
        "    \"R Score (Test)\": test_r2,\n",
        "    \"MAE\": mae_value,\n",
        "    \"MdSE\": mdse_value\n",
        "}\n",
        "\n",
        "results\n"
      ],
      "metadata": {
        "id": "kdrNNJll8q9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Plot residuals and prediction errors similar to reference images\n",
        "\n",
        "# Residuals Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Residuals\n",
        "plt.subplot(1, 2, 1)\n",
        "train_residuals = y_train - train_predictions\n",
        "test_residuals = y_test - test_predictions\n",
        "\n",
        "sns.residplot(x=train_predictions, y=train_residuals, lowess=True, color=\"blue\", label=f'Train $R^2$ = {train_r2:.3f}')\n",
        "sns.residplot(x=test_predictions, y=test_residuals, lowess=True, color=\"green\", label=f'Test $R^2$ = {test_r2:.3f}')\n",
        "\n",
        "plt.axhline(y=0, color='black', linestyle='--')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals for Logistic Regression Model')\n",
        "plt.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, test_predictions, label=f'$R^2$ = {test_r2:.3f}', alpha=0.7, edgecolors='b')\n",
        "plt.plot([0, 1], [0, 1], '--', color='black')\n",
        "plt.plot([0, 1], [0.5, 0.5], '--', color='gray')\n",
        "plt.xlabel('$y$')\n",
        "plt.ylabel('$\\hat{y}$')\n",
        "plt.title('Prediction Error for Logistic Regression')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5TMK6e7N85-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# Calculate probabilities for the test set\n",
        "test_probabilities = lr_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC score\n",
        "fpr, tpr, thresholds = roc_curve(y_test, test_probabilities)\n",
        "roc_auc = roc_auc_score(y_test, test_probabilities)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'Logistic Regression (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VjJazBpP89Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "conf_matrix = ConfusionMatrixDisplay.from_estimator(\n",
        "    lr_model, X_test, y_test, display_labels=['Low Removal', 'High Removal'], cmap='Blues', values_format='d'\n",
        ")\n",
        "conf_matrix.ax_.set_title(\"Confusion Matrix for Logistic Regression\")\n",
        "plt.grid(False)  # Turn off grid for better readability\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JzEjAIjI_Zq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are working with the latest file\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Recalculate the removal efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Multiple Linear Regression\n",
        "mlr_features = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                     'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                     'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "mlr_target = data['Removal Efficiency BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_mlr, X_test_mlr, y_train_mlr, y_test_mlr = train_test_split(mlr_features, mlr_target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Multiple Linear Regression model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "mlr_model = LinearRegression()\n",
        "mlr_model.fit(X_train_mlr, y_train_mlr)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_mlr = mlr_model.predict(X_train_mlr)\n",
        "test_predictions_mlr = mlr_model.predict(X_test_mlr)\n",
        "\n",
        "# Calculate metrics\n",
        "train_r2_mlr = r2_score(y_train_mlr, train_predictions_mlr)\n",
        "test_r2_mlr = r2_score(y_test_mlr, test_predictions_mlr)\n",
        "mae_value_mlr = mean_absolute_error(y_test_mlr, test_predictions_mlr)\n",
        "mdse_value_mlr = median_absolute_error(y_test_mlr, test_predictions_mlr)\n",
        "\n",
        "# Calculate accuracy as the percentage of predictions within a tolerance range (e.g.,  0.1 of actual value)\n",
        "tolerance = 0.1\n",
        "train_accuracy_mlr = np.mean(np.abs(y_train_mlr - train_predictions_mlr) <= tolerance)\n",
        "test_accuracy_mlr = np.mean(np.abs(y_test_mlr - test_predictions_mlr) <= tolerance)\n",
        "\n",
        "# Results\n",
        "mlr_results = {\n",
        "    \"Accuracy (Train)\": train_accuracy_mlr,\n",
        "    \"Accuracy (Test)\": test_accuracy_mlr,\n",
        "    \"R Score (Train)\": train_r2_mlr,\n",
        "    \"R Score (Test)\": test_r2_mlr,\n",
        "    \"MAE\": mae_value_mlr,\n",
        "    \"MdSE\": mdse_value_mlr\n",
        "}\n",
        "\n",
        "mlr_results\n"
      ],
      "metadata": {
        "id": "YGelRgI6_dV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals and Prediction Errors similar to reference images\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Residuals\n",
        "plt.subplot(1, 2, 1)\n",
        "train_residuals_mlr = y_train_mlr - train_predictions_mlr\n",
        "test_residuals_mlr = y_test_mlr - test_predictions_mlr\n",
        "\n",
        "# Residuals plot with histogram distribution\n",
        "sns.residplot(x=train_predictions_mlr, y=train_residuals_mlr, lowess=True, color=\"blue\", label=f'Train $R^2$ = {train_r2_mlr:.3f}')\n",
        "sns.residplot(x=test_predictions_mlr, y=test_residuals_mlr, lowess=True, color=\"green\", label=f'Test $R^2$ = {test_r2_mlr:.3f}')\n",
        "plt.axhline(y=0, color='black', linestyle='--')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals for Multiple Linear Regression Model')\n",
        "plt.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test_mlr, test_predictions_mlr, label=f'$R^2$ = {test_r2_mlr:.3f}', alpha=0.7, edgecolors='b')\n",
        "plt.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "plt.plot([0, 1], [np.mean(test_predictions_mlr), np.mean(test_predictions_mlr)], '--', color='gray', label='best fit')\n",
        "plt.xlabel('$y$')\n",
        "plt.ylabel('$\\hat{y}$')\n",
        "plt.title('Prediction Error for Multiple Linear Regression')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Q8cb-ggy_eHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# For ROC curve, we'll need a binary classification setup. Here, we need to create a threshold for the target variable.\n",
        "# Let's assume a high removal efficiency is above 0.95, similar to the earlier classification approach.\n",
        "\n",
        "# Binary classification target based on a threshold for high/low removal efficiency\n",
        "mlr_target_binary = (mlr_target > 0.95).astype(int)\n",
        "\n",
        "# Re-train the MLR model for binary classification context\n",
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(mlr_features, mlr_target_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train logistic regression model for binary classification\n",
        "mlr_binary_model = LogisticRegression(max_iter=1000)\n",
        "mlr_binary_model.fit(X_train_bin, y_train_bin)\n",
        "\n",
        "# Calculate probabilities for the test set\n",
        "test_probabilities_bin = mlr_binary_model.predict_proba(X_test_bin)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC score\n",
        "fpr_bin, tpr_bin, thresholds_bin = roc_curve(y_test_bin, test_probabilities_bin)\n",
        "roc_auc_bin = roc_auc_score(y_test_bin, test_probabilities_bin)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_bin, tpr_bin, color='blue', label=f'Logistic Regression (AUC = {roc_auc_bin:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for MLR as Binary Classification')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SxJkQgQb_jXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use a different threshold for high removal efficiency, e.g., 0.90.\n",
        "# Binary classification target based on a new threshold for high/low removal efficiency\n",
        "mlr_target_binary_adjusted = (mlr_target > 0.90).astype(int)\n",
        "\n",
        "# Re-train the model with the new binary classification target\n",
        "X_train_bin_adj, X_test_bin_adj, y_train_bin_adj, y_test_bin_adj = train_test_split(mlr_features, mlr_target_binary_adjusted, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train logistic regression model for binary classification with the new threshold\n",
        "mlr_binary_model_adjusted = LogisticRegression(max_iter=1000)\n",
        "mlr_binary_model_adjusted.fit(X_train_bin_adj, y_train_bin_adj)\n",
        "\n",
        "# Calculate probabilities for the test set with the adjusted model\n",
        "test_probabilities_bin_adj = mlr_binary_model_adjusted.predict_proba(X_test_bin_adj)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC score with adjusted target\n",
        "fpr_bin_adj, tpr_bin_adj, thresholds_bin_adj = roc_curve(y_test_bin_adj, test_probabilities_bin_adj)\n",
        "roc_auc_bin_adj = roc_auc_score(y_test_bin_adj, test_probabilities_bin_adj)\n",
        "\n",
        "# Plot ROC curve with the new threshold\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_bin_adj, tpr_bin_adj, color='blue', label=f'Logistic Regression (AUC = {roc_auc_bin_adj:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve with Adjusted Threshold (0.90) for High Removal Efficiency')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "s2SZGU5x_kRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Reload the dataset to ensure we are using the most recent version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Random Forest Regression\n",
        "rf_features = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                     'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                     'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "rf_target = data['Removal Efficiency BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(rf_features, rf_target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Regression model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_rf = rf_model.predict(X_train_rf)\n",
        "test_predictions_rf = rf_model.predict(X_test_rf)\n",
        "\n",
        "# Calculate metrics\n",
        "train_r2_rf = r2_score(y_train_rf, train_predictions_rf)\n",
        "test_r2_rf = r2_score(y_test_rf, test_predictions_rf)\n",
        "mae_value_rf = mean_absolute_error(y_test_rf, test_predictions_rf)\n",
        "mdse_value_rf = median_absolute_error(y_test_rf, test_predictions_rf)\n",
        "\n",
        "# Calculate accuracy as the percentage of predictions within a tolerance range (e.g.,  0.1 of actual value)\n",
        "train_accuracy_rf = np.mean(np.abs(y_train_rf - train_predictions_rf) <= tolerance)\n",
        "test_accuracy_rf = np.mean(np.abs(y_test_rf - test_predictions_rf) <= tolerance)\n",
        "\n",
        "# Results\n",
        "rf_results = {\n",
        "    \"Accuracy (Train)\": train_accuracy_rf,\n",
        "    \"Accuracy (Test)\": test_accuracy_rf,\n",
        "    \"R Score (Train)\": train_r2_rf,\n",
        "    \"R Score (Test)\": test_r2_rf,\n",
        "    \"MAE\": mae_value_rf,\n",
        "    \"MdSE\": mdse_value_rf\n",
        "}\n",
        "\n",
        "rf_results\n"
      ],
      "metadata": {
        "id": "vwC0lpm5_qQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals and Prediction Errors similar to reference images for Random Forest\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Residuals Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "train_residuals_rf = y_train_rf - train_predictions_rf\n",
        "test_residuals_rf = y_test_rf - test_predictions_rf\n",
        "\n",
        "# Residuals plot with histogram distribution\n",
        "sns.residplot(x=train_predictions_rf, y=train_residuals_rf, lowess=True, color=\"blue\", label=f'Train $R^2$ = {train_r2_rf:.3f}')\n",
        "sns.residplot(x=test_predictions_rf, y=test_residuals_rf, lowess=True, color=\"green\", label=f'Test $R^2$ = {test_r2_rf:.3f}')\n",
        "plt.axhline(y=0, color='black', linestyle='--')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals for Random Forest Regression Model')\n",
        "plt.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test_rf, test_predictions_rf, label=f'$R^2$ = {test_r2_rf:.3f}', alpha=0.7, edgecolors='b')\n",
        "plt.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "plt.plot([0, 1], [np.mean(test_predictions_rf), np.mean(test_predictions_rf)], '--', color='gray', label='best fit')\n",
        "plt.xlabel('$y$')\n",
        "plt.ylabel('$\\hat{y}$')\n",
        "plt.title('Prediction Error for Random Forest Regression')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SJe35JhzCcVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate feature importance in Random Forest model\n",
        "feature_importance_rf = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "features_df = pd.DataFrame({\n",
        "    'Feature': rf_features.columns,\n",
        "    'Importance': feature_importance_rf\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display feature importance\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Feature Importance in Random Forest\", dataframe=features_df)\n"
      ],
      "metadata": {
        "id": "FGLTfspXCgVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the feature importance as a bar chart\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=features_df, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Random Forest Model')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ANVPDiZ7ChTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Reload the dataset to ensure we are using the most recent version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Gradient Boosting Regression\n",
        "gb_features = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                    'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                    'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "gb_target = data['Removal Efficiency BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_gb, X_test_gb, y_train_gb, y_test_gb = train_test_split(gb_features, gb_target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting Regression model\n",
        "gb_model = GradientBoostingRegressor(random_state=42)\n",
        "gb_model.fit(X_train_gb, y_train_gb)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_gb = gb_model.predict(X_train_gb)\n",
        "test_predictions_gb = gb_model.predict(X_test_gb)\n",
        "\n",
        "# Calculate metrics\n",
        "train_r2_gb = r2_score(y_train_gb, train_predictions_gb)\n",
        "test_r2_gb = r2_score(y_test_gb, test_predictions_gb)\n",
        "mae_value_gb = mean_absolute_error(y_test_gb, test_predictions_gb)\n",
        "mdse_value_gb = median_absolute_error(y_test_gb, test_predictions_gb)\n",
        "\n",
        "# Calculate accuracy as the percentage of predictions within a tolerance range (e.g.,  0.1 of actual value)\n",
        "train_accuracy_gb = np.mean(np.abs(y_train_gb - train_predictions_gb) <= tolerance)\n",
        "test_accuracy_gb = np.mean(np.abs(y_test_gb - test_predictions_gb) <= tolerance)\n",
        "\n",
        "# Results\n",
        "gb_results = {\n",
        "    \"Accuracy (Train)\": train_accuracy_gb,\n",
        "    \"Accuracy (Test)\": test_accuracy_gb,\n",
        "    \"R Score (Train)\": train_r2_gb,\n",
        "    \"R Score (Test)\": test_r2_gb,\n",
        "    \"MAE\": mae_value_gb,\n",
        "    \"MdSE\": mdse_value_gb\n",
        "}\n",
        "\n",
        "gb_results\n"
      ],
      "metadata": {
        "id": "BCctt5AXCnUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals and Prediction Errors similar to reference images for Gradient Boosting\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Residuals Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "train_residuals_gb = y_train_gb - train_predictions_gb\n",
        "test_residuals_gb = y_test_gb - test_predictions_gb\n",
        "\n",
        "# Residuals plot with histogram distribution\n",
        "sns.residplot(x=train_predictions_gb, y=train_residuals_gb, lowess=True, color=\"blue\", label=f'Train $R^2$ = {train_r2_gb:.3f}')\n",
        "sns.residplot(x=test_predictions_gb, y=test_residuals_gb, lowess=True, color=\"green\", label=f'Test $R^2$ = {test_r2_gb:.3f}')\n",
        "plt.axhline(y=0, color='black', linestyle='--')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals for Gradient Boosting Regression Model')\n",
        "plt.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test_gb, test_predictions_gb, label=f'$R^2$ = {test_r2_gb:.3f}', alpha=0.7, edgecolors='b')\n",
        "plt.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "plt.plot([0, 1], [np.mean(test_predictions_gb), np.mean(test_predictions_gb)], '--', color='gray', label='best fit')\n",
        "plt.xlabel('$y$')\n",
        "plt.ylabel('$\\hat{y}$')\n",
        "plt.title('Prediction Error for Gradient Boosting Regression')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6fFLB8n0Cqz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# Reload the dataset to ensure we are using the most recent version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Support Vector Regression (SVR)\n",
        "svr_features = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                    'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                    'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "svr_target = data['Removal Efficiency BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_svr, X_test_svr, y_train_svr, y_test_svr = train_test_split(svr_features, svr_target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Support Vector Regression model\n",
        "svr_model = SVR(kernel='rbf')  # Using radial basis function kernel\n",
        "svr_model.fit(X_train_svr, y_train_svr)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_svr = svr_model.predict(X_train_svr)\n",
        "test_predictions_svr = svr_model.predict(X_test_svr)\n",
        "\n",
        "# Calculate metrics\n",
        "train_r2_svr = r2_score(y_train_svr, train_predictions_svr)\n",
        "test_r2_svr = r2_score(y_test_svr, test_predictions_svr)\n",
        "mae_value_svr = mean_absolute_error(y_test_svr, test_predictions_svr)\n",
        "mdse_value_svr = median_absolute_error(y_test_svr, test_predictions_svr)\n",
        "\n",
        "# Calculate accuracy as the percentage of predictions within a tolerance range (e.g.,  0.1 of actual value)\n",
        "train_accuracy_svr = np.mean(np.abs(y_train_svr - train_predictions_svr) <= tolerance)\n",
        "test_accuracy_svr = np.mean(np.abs(y_test_svr - test_predictions_svr) <= tolerance)\n",
        "\n",
        "# Results\n",
        "svr_results = {\n",
        "    \"Accuracy (Train)\": train_accuracy_svr,\n",
        "    \"Accuracy (Test)\": test_accuracy_svr,\n",
        "    \"R Score (Train)\": train_r2_svr,\n",
        "    \"R Score (Test)\": test_r2_svr,\n",
        "    \"MAE\": mae_value_svr,\n",
        "    \"MdSE\": mdse_value_svr\n",
        "}\n",
        "\n",
        "svr_results\n"
      ],
      "metadata": {
        "id": "vOj3tiivCt94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals and Prediction Errors similar to reference images for Support Vector Regression\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Residuals Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "train_residuals_svr = y_train_svr - train_predictions_svr\n",
        "test_residuals_svr = y_test_svr - test_predictions_svr\n",
        "\n",
        "# Residuals plot with histogram distribution\n",
        "sns.residplot(x=train_predictions_svr, y=train_residuals_svr, lowess=True, color=\"blue\", label=f'Train $R^2$ = {train_r2_svr:.3f}')\n",
        "sns.residplot(x=test_predictions_svr, y=test_residuals_svr, lowess=True, color=\"green\", label=f'Test $R^2$ = {test_r2_svr:.3f}')\n",
        "plt.axhline(y=0, color='black', linestyle='--')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals for Support Vector Regression Model')\n",
        "plt.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test_svr, test_predictions_svr, label=f'$R^2$ = {test_r2_svr:.3f}', alpha=0.7, edgecolors='b')\n",
        "plt.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "plt.plot([0, 1], [np.mean(test_predictions_svr), np.mean(test_predictions_svr)], '--', color='gray', label='best fit')\n",
        "plt.xlabel('$y$')\n",
        "plt.ylabel('$\\hat{y}$')\n",
        "plt.title('Prediction Error for Support Vector Regression')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5lkrbGENCx67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals and Prediction Errors similar to reference images for Logistic Regression (COD)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Residuals Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "train_residuals_cod = y_train_cod - train_predictions_cod\n",
        "test_residuals_cod = y_test_cod - test_predictions_cod\n",
        "\n",
        "# Residuals plot with histogram distribution\n",
        "sns.residplot(x=train_predictions_cod, y=train_residuals_cod, lowess=True, color=\"blue\", label=f'Train $R^2$ = {train_r2_cod:.3f}')\n",
        "sns.residplot(x=test_predictions_cod, y=test_residuals_cod, lowess=True, color=\"green\", label=f'Test $R^2$ = {test_r2_cod:.3f}')\n",
        "plt.axhline(y=0, color='black', linestyle='--')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals for Logistic Regression Model (COD)')\n",
        "plt.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test_cod, test_predictions_cod, label=f'$R^2$ = {test_r2_cod:.3f}', alpha=0.7, edgecolors='b')\n",
        "plt.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "plt.plot([0, 1], [np.mean(test_predictions_cod), np.mean(test_predictions_cod)], '--', color='gray', label='best fit')\n",
        "plt.xlabel('$y$')\n",
        "plt.ylabel('$\\hat{y}$')\n",
        "plt.title('Prediction Error for Logistic Regression (COD)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FZLiQpvbC1hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing comparison data for multiple models on BOD removal efficiency\n",
        "\n",
        "# Re-load the dataset\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Define features and target\n",
        "features_bod = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                     'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                     'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "target_bod = data['Removal Efficiency BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_bod, X_test_bod, y_train_bod, y_test_bod = train_test_split(features_bod, target_bod, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train and evaluate models\n",
        "models = {\n",
        "    \"Multiple Linear Regression\": LinearRegression(),\n",
        "    \"Support Vector Regression\": SVR(kernel='rbf'),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "# Loop through each model, train and evaluate\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train_bod, y_train_bod)\n",
        "    train_preds = model.predict(X_train_bod)\n",
        "    test_preds = model.predict(X_test_bod)\n",
        "\n",
        "    train_r2 = r2_score(y_train_bod, train_preds)\n",
        "    test_r2 = r2_score(y_test_bod, test_preds)\n",
        "    mae = mean_absolute_error(y_test_bod, test_preds)\n",
        "    mdse = median_absolute_error(y_test_bod, test_preds)\n",
        "    train_acc = np.mean(np.abs(y_train_bod - train_preds) <= tolerance)\n",
        "    test_acc = np.mean(np.abs(y_test_bod - test_preds) <= tolerance)\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Train R\": train_r2,\n",
        "        \"Test R\": test_r2,\n",
        "        \"MAE\": mae,\n",
        "        \"MdSE\": mdse,\n",
        "        \"Train Accuracy\": train_acc,\n",
        "        \"Test Accuracy\": test_acc\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame for visualization\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display the results\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Model Comparison for BOD Removal Efficiency\", dataframe=results_df)\n"
      ],
      "metadata": {
        "id": "w6qB28MNDN6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual comparison using bar charts for R scores and MAE\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Subplot 1: R Scores Comparison\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(data=results_df, x='Model', y='Test R', palette='viridis')\n",
        "plt.title('Test R Score Comparison')\n",
        "plt.ylabel('R Score')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 2: MAE Comparison\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(data=results_df, x='Model', y='MAE', palette='viridis')\n",
        "plt.title('Mean Absolute Error (MAE) Comparison')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vlZAFNbZDT07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the latest dataset\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for COD\n",
        "data['Removal Efficiency COD'] = (data['In-CODcr\\n(mg/L)'] - data['Ef-CODcr\\n(mg/L)']) / data['In-CODcr\\n(mg/L)']\n",
        "\n",
        "# Create a binary target variable for logistic regression, similar to previous approach\n",
        "threshold_cod = data['Removal Efficiency COD'].median()\n",
        "data['High Removal COD'] = (data['Removal Efficiency COD'] >= threshold_cod).astype(int)\n",
        "\n",
        "# Define features and target for logistic regression\n",
        "features_cod = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                     'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                     'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_cod = data['High Removal COD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_cod, X_test_cod, y_train_cod, y_test_cod = train_test_split(features_cod, target_cod, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model_cod = LogisticRegression(max_iter=1000)\n",
        "lr_model_cod.fit(X_train_cod, y_train_cod)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_cod = lr_model_cod.predict(X_train_cod)\n",
        "test_predictions_cod = lr_model_cod.predict(X_test_cod)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_cod = accuracy_score(y_train_cod, train_predictions_cod)\n",
        "test_accuracy_cod = accuracy_score(y_test_cod, test_predictions_cod)\n",
        "\n",
        "train_r2_cod = r2_score(y_train_cod, train_predictions_cod)\n",
        "test_r2_cod = r2_score(y_test_cod, test_predictions_cod)\n",
        "\n",
        "mae_value_cod = mean_absolute_error(y_test_cod, test_predictions_cod)\n",
        "mdse_value_cod = median_absolute_error(y_test_cod, test_predictions_cod)\n",
        "\n",
        "# Display results\n",
        "lr_results_cod = {\n",
        "    \"Accuracy (Train)\": train_accuracy_cod,\n",
        "    \"Accuracy (Test)\": test_accuracy_cod,\n",
        "    \"R Score (Train)\": train_r2_cod,\n",
        "    \"R Score (Test)\": test_r2_cod,\n",
        "    \"MAE\": mae_value_cod,\n",
        "    \"MdSE\": mdse_value_cod\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_cod = y_train_cod - train_predictions_cod\n",
        "test_residuals_cod = y_test_cod - test_predictions_cod\n",
        "\n",
        "lr_results_cod\n"
      ],
      "metadata": {
        "id": "1JRI0hZZDaZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals and Prediction Errors similar to reference images for Logistic Regression (COD)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals Plot with distribution\n",
        "sns.residplot(x=train_predictions_cod, y=train_residuals_cod, lowess=True, color=\"blue\",\n",
        "              label=f'Train $R^2$ = {train_r2_cod:.3f}', ax=ax1)\n",
        "sns.residplot(x=test_predictions_cod, y=test_residuals_cod, lowess=True, color=\"green\",\n",
        "              label=f'Test $R^2$ = {test_r2_cod:.3f}', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals for Logistic Regression Model (COD)')\n",
        "ax1.legend()\n",
        "\n",
        "# Distribution plot\n",
        "sns.histplot(train_residuals_cod, kde=True, color=\"blue\", label=\"Train Residuals\", ax=ax1, bins=20, stat=\"density\", alpha=0.3)\n",
        "sns.histplot(test_residuals_cod, kde=True, color=\"green\", label=\"Test Residuals\", ax=ax1, bins=20, stat=\"density\", alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_cod, test_predictions_cod, label=f'$R^2$ = {test_r2_cod:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_cod), np.mean(test_predictions_cod)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Logistic Regression (COD)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NAi-1uYGDdAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for COD\n",
        "data['Removal Efficiency COD'] = (data['In-CODcr\\n(mg/L)'] - data['Ef-CODcr\\n(mg/L)']) / data['In-CODcr\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Logistic Regression (using continuous removal efficiency for regression)\n",
        "features_cod_reg = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                         'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                         'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_cod_reg = data['Removal Efficiency COD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_cod_reg, X_test_cod_reg, y_train_cod_reg, y_test_cod_reg = train_test_split(features_cod_reg, target_cod_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Linear Regression model (used as Logistic Regression isn't suitable for continuous target)\n",
        "lr_model_cod_reg = LinearRegression()\n",
        "lr_model_cod_reg.fit(X_train_cod_reg, y_train_cod_reg)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_cod_reg = lr_model_cod_reg.predict(X_train_cod_reg)\n",
        "test_predictions_cod_reg = lr_model_cod_reg.predict(X_test_cod_reg)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_cod_reg = np.mean(np.abs(y_train_cod_reg - train_predictions_cod_reg) <= tolerance)\n",
        "test_accuracy_cod_reg = np.mean(np.abs(y_test_cod_reg - test_predictions_cod_reg) <= tolerance)\n",
        "\n",
        "train_r2_cod_reg = r2_score(y_train_cod_reg, train_predictions_cod_reg)\n",
        "test_r2_cod_reg = r2_score(y_test_cod_reg, test_predictions_cod_reg)\n",
        "\n",
        "mae_value_cod_reg = mean_absolute_error(y_test_cod_reg, test_predictions_cod_reg)\n",
        "mdse_value_cod_reg = median_absolute_error(y_test_cod_reg, test_predictions_cod_reg)\n",
        "\n",
        "# Display results\n",
        "lr_results_cod_reg = {\n",
        "    \"Accuracy (Train)\": train_accuracy_cod_reg,\n",
        "    \"Accuracy (Test)\": test_accuracy_cod_reg,\n",
        "    \"R Score (Train)\": train_r2_cod_reg,\n",
        "    \"R Score (Test)\": test_r2_cod_reg,\n",
        "    \"MAE\": mae_value_cod_reg,\n",
        "    \"MdSE\": mdse_value_cod_reg\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_cod_reg = y_train_cod_reg - train_predictions_cod_reg\n",
        "test_residuals_cod_reg = y_test_cod_reg - test_predictions_cod_reg\n",
        "\n",
        "lr_results_cod_reg\n"
      ],
      "metadata": {
        "id": "xdVkMf3ADfRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Linear Regression (COD)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_cod_reg, y=train_residuals_cod_reg, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_cod_reg, y=test_residuals_cod_reg, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Linear Regression (COD)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_cod_reg, test_predictions_cod_reg, label=f'$R^2$ = {test_r2_cod_reg:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_cod_reg), np.mean(test_predictions_cod_reg)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Linear Regression (COD)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v9OvaDVbDjRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for COD\n",
        "data['Removal Efficiency COD'] = (data['In-CODcr\\n(mg/L)'] - data['Ef-CODcr\\n(mg/L)']) / data['In-CODcr\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Random Forest Regression\n",
        "features_cod_rf = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                        'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                        'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_cod_rf = data['Removal Efficiency COD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_cod_rf, X_test_cod_rf, y_train_cod_rf, y_test_cod_rf = train_test_split(features_cod_rf, target_cod_rf, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Regression model\n",
        "rf_model_cod = RandomForestRegressor(random_state=42)\n",
        "rf_model_cod.fit(X_train_cod_rf, y_train_cod_rf)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_cod_rf = rf_model_cod.predict(X_train_cod_rf)\n",
        "test_predictions_cod_rf = rf_model_cod.predict(X_test_cod_rf)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_cod_rf = np.mean(np.abs(y_train_cod_rf - train_predictions_cod_rf) <= tolerance)\n",
        "test_accuracy_cod_rf = np.mean(np.abs(y_test_cod_rf - test_predictions_cod_rf) <= tolerance)\n",
        "\n",
        "train_r2_cod_rf = r2_score(y_train_cod_rf, train_predictions_cod_rf)\n",
        "test_r2_cod_rf = r2_score(y_test_cod_rf, test_predictions_cod_rf)\n",
        "\n",
        "mae_value_cod_rf = mean_absolute_error(y_test_cod_rf, test_predictions_cod_rf)\n",
        "mdse_value_cod_rf = median_absolute_error(y_test_cod_rf, test_predictions_cod_rf)\n",
        "\n",
        "# Display results\n",
        "rf_results_cod = {\n",
        "    \"Accuracy (Train)\": train_accuracy_cod_rf,\n",
        "    \"Accuracy (Test)\": test_accuracy_cod_rf,\n",
        "    \"R Score (Train)\": train_r2_cod_rf,\n",
        "    \"R Score (Test)\": test_r2_cod_rf,\n",
        "    \"MAE\": mae_value_cod_rf,\n",
        "    \"MdSE\": mdse_value_cod_rf\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_cod_rf = y_train_cod_rf - train_predictions_cod_rf\n",
        "test_residuals_cod_rf = y_test_cod_rf - test_predictions_cod_rf\n",
        "\n",
        "rf_results_cod\n"
      ],
      "metadata": {
        "id": "X0XuWESXDkFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Random Forest (COD)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_cod_rf, y=train_residuals_cod_rf, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_cod_rf, y=test_residuals_cod_rf, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Random Forest (COD)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_cod_rf, test_predictions_cod_rf, label=f'$R^2$ = {test_r2_cod_rf:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_cod_rf), np.mean(test_predictions_cod_rf)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Random Forest (COD)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "r6FeBzjHDqoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for COD\n",
        "data['Removal Efficiency COD'] = (data['In-CODcr\\n(mg/L)'] - data['Ef-CODcr\\n(mg/L)']) / data['In-CODcr\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Gradient Boosting Regression\n",
        "features_cod_gb = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                        'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                        'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_cod_gb = data['Removal Efficiency COD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_cod_gb, X_test_cod_gb, y_train_cod_gb, y_test_cod_gb = train_test_split(features_cod_gb, target_cod_gb, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting Regression model\n",
        "gb_model_cod = GradientBoostingRegressor(random_state=42)\n",
        "gb_model_cod.fit(X_train_cod_gb, y_train_cod_gb)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_cod_gb = gb_model_cod.predict(X_train_cod_gb)\n",
        "test_predictions_cod_gb = gb_model_cod.predict(X_test_cod_gb)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_cod_gb = np.mean(np.abs(y_train_cod_gb - train_predictions_cod_gb) <= tolerance)\n",
        "test_accuracy_cod_gb = np.mean(np.abs(y_test_cod_gb - test_predictions_cod_gb) <= tolerance)\n",
        "\n",
        "train_r2_cod_gb = r2_score(y_train_cod_gb, train_predictions_cod_gb)\n",
        "test_r2_cod_gb = r2_score(y_test_cod_gb, test_predictions_cod_gb)\n",
        "\n",
        "mae_value_cod_gb = mean_absolute_error(y_test_cod_gb, test_predictions_cod_gb)\n",
        "mdse_value_cod_gb = median_absolute_error(y_test_cod_gb, test_predictions_cod_gb)\n",
        "\n",
        "# Display results\n",
        "gb_results_cod = {\n",
        "    \"Accuracy (Train)\": train_accuracy_cod_gb,\n",
        "    \"Accuracy (Test)\": test_accuracy_cod_gb,\n",
        "    \"R Score (Train)\": train_r2_cod_gb,\n",
        "    \"R Score (Test)\": test_r2_cod_gb,\n",
        "    \"MAE\": mae_value_cod_gb,\n",
        "    \"MdSE\": mdse_value_cod_gb\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_cod_gb = y_train_cod_gb - train_predictions_cod_gb\n",
        "test_residuals_cod_gb = y_test_cod_gb - test_predictions_cod_gb\n",
        "\n",
        "gb_results_cod\n"
      ],
      "metadata": {
        "id": "10SFzMd4DtSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Gradient Boosting (COD)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_cod_gb, y=train_residuals_cod_gb, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_cod_gb, y=test_residuals_cod_gb, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Gradient Boosting (COD)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_cod_gb, test_predictions_cod_gb, label=f'$R^2$ = {test_r2_cod_gb:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_cod_gb), np.mean(test_predictions_cod_gb)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Gradient Boosting (COD)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k0fdylY3DuEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for COD\n",
        "data['Removal Efficiency COD'] = (data['In-CODcr\\n(mg/L)'] - data['Ef-CODcr\\n(mg/L)']) / data['In-CODcr\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Support Vector Regression\n",
        "features_cod_svr = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                        'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                        'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_cod_svr = data['Removal Efficiency COD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_cod_svr, X_test_cod_svr, y_train_cod_svr, y_test_cod_svr = train_test_split(features_cod_svr, target_cod_svr, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Support Vector Regression model\n",
        "svr_model_cod = SVR(kernel='rbf')\n",
        "svr_model_cod.fit(X_train_cod_svr, y_train_cod_svr)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_cod_svr = svr_model_cod.predict(X_train_cod_svr)\n",
        "test_predictions_cod_svr = svr_model_cod.predict(X_test_cod_svr)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_cod_svr = np.mean(np.abs(y_train_cod_svr - train_predictions_cod_svr) <= tolerance)\n",
        "test_accuracy_cod_svr = np.mean(np.abs(y_test_cod_svr - test_predictions_cod_svr) <= tolerance)\n",
        "\n",
        "train_r2_cod_svr = r2_score(y_train_cod_svr, train_predictions_cod_svr)\n",
        "test_r2_cod_svr = r2_score(y_test_cod_svr, test_predictions_cod_svr)\n",
        "\n",
        "mae_value_cod_svr = mean_absolute_error(y_test_cod_svr, test_predictions_cod_svr)\n",
        "mdse_value_cod_svr = median_absolute_error(y_test_cod_svr, test_predictions_cod_svr)\n",
        "\n",
        "# Display results\n",
        "svr_results_cod = {\n",
        "    \"Accuracy (Train)\": train_accuracy_cod_svr,\n",
        "    \"Accuracy (Test)\": test_accuracy_cod_svr,\n",
        "    \"R Score (Train)\": train_r2_cod_svr,\n",
        "    \"R Score (Test)\": test_r2_cod_svr,\n",
        "    \"MAE\": mae_value_cod_svr,\n",
        "    \"MdSE\": mdse_value_cod_svr\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_cod_svr = y_train_cod_svr - train_predictions_cod_svr\n",
        "test_residuals_cod_svr = y_test_cod_svr - test_predictions_cod_svr\n",
        "\n",
        "svr_results_cod\n"
      ],
      "metadata": {
        "id": "6yGiw9s-Dz6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Support Vector Regression (COD)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_cod_svr, y=train_residuals_cod_svr, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_cod_svr, y=test_residuals_cod_svr, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Support Vector Regression (COD)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_cod_svr, test_predictions_cod_svr, label=f'$R^2$ = {test_r2_cod_svr:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_cod_svr), np.mean(test_predictions_cod_svr)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Support Vector Regression (COD)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6H7FbnumD3ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for COD\n",
        "data['Removal Efficiency COD'] = (data['In-CODcr\\n(mg/L)'] - data['Ef-CODcr\\n(mg/L)']) / data['In-CODcr\\n(mg/L)']\n",
        "\n",
        "# Define features and target\n",
        "features_cod_all = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                         'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                         'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "target_cod_all = data['Removal Efficiency COD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_cod_all, X_test_cod_all, y_train_cod_all, y_test_cod_all = train_test_split(features_cod_all, target_cod_all, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define models for comparison\n",
        "models_cod = {\n",
        "    \"Multiple Linear Regression\": LinearRegression(),\n",
        "    \"Support Vector Regression\": SVR(kernel='rbf'),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results_cod_all = []\n",
        "\n",
        "for model_name, model in models_cod.items():\n",
        "    model.fit(X_train_cod_all, y_train_cod_all)\n",
        "    train_preds_all = model.predict(X_train_cod_all)\n",
        "    test_preds_all = model.predict(X_test_cod_all)\n",
        "\n",
        "    train_r2_all = r2_score(y_train_cod_all, train_preds_all)\n",
        "    test_r2_all = r2_score(y_test_cod_all, test_preds_all)\n",
        "    mae_all = mean_absolute_error(y_test_cod_all, test_preds_all)\n",
        "    mdse_all = median_absolute_error(y_test_cod_all, test_preds_all)\n",
        "    train_acc_all = np.mean(np.abs(y_train_cod_all - train_preds_all) <= tolerance)\n",
        "    test_acc_all = np.mean(np.abs(y_test_cod_all - test_preds_all) <= tolerance)\n",
        "\n",
        "    results_cod_all.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Train R\": train_r2_all,\n",
        "        \"Test R\": test_r2_all,\n",
        "        \"MAE\": mae_all,\n",
        "        \"MdSE\": mdse_all,\n",
        "        \"Train Accuracy\": train_acc_all,\n",
        "        \"Test Accuracy\": test_acc_all\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame for visualization\n",
        "results_cod_df = pd.DataFrame(results_cod_all)\n",
        "\n",
        "# Display the results\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Model Comparison for COD Removal Efficiency\", dataframe=results_cod_df)\n"
      ],
      "metadata": {
        "id": "LSwIqd89D6bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual comparison using bar charts for R scores and MAE\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Subplot 1: R Scores Comparison\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(data=results_cod_df, x='Model', y='Test R', palette='viridis')\n",
        "plt.title('Test R Score Comparison for COD')\n",
        "plt.ylabel('R Score')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 2: MAE Comparison\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(data=results_cod_df, x='Model', y='MAE', palette='viridis')\n",
        "plt.title('Mean Absolute Error (MAE) Comparison for COD')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UnIOH8tSD6_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual comparison including R Scores, MAE, and Accuracy for COD removal efficiency\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "\n",
        "# Subplot 1: Comparison of R Scores by Models\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(data=results_cod_df, x='Model', y='Test R', palette='viridis')\n",
        "plt.title('Comparison Of R Scores By Models for COD')\n",
        "plt.ylabel('R Score')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 2: Comparison of Mean Absolute Error (MAE) by Models\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(data=results_cod_df, x='Model', y='MAE', palette='viridis')\n",
        "plt.title('Comparison of Mean Absolute Error (MAE) by Models for COD')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 3: Comparison Of Accuracy By Models\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(data=results_cod_df, x='Model', y='Test Accuracy', palette='viridis')\n",
        "plt.title('Comparison Of Accuracy By Models for COD')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(rotation=15)\n",
        "plt.ylim(0.9, 1.05)  # Zooming in to better visualize the differences\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zInZ3MGCEAvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for SS\n",
        "data['Removal Efficiency SS'] = (data['In-SS\\n(mg/L)'] - data['Ef-SS\\n(mg/L)']) / data['In-SS\\n(mg/L)']\n",
        "\n",
        "# Create a binary target variable for logistic regression, similar to previous approach\n",
        "threshold_ss = data['Removal Efficiency SS'].median()\n",
        "data['High Removal SS'] = (data['Removal Efficiency SS'] >= threshold_ss).astype(int)\n",
        "\n",
        "# Define features and target for logistic regression\n",
        "features_ss = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                    'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                    'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_ss = data['High Removal SS']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_ss, X_test_ss, y_train_ss, y_test_ss = train_test_split(features_ss, target_ss, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model_ss = LogisticRegression(max_iter=1000)\n",
        "lr_model_ss.fit(X_train_ss, y_train_ss)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_ss = lr_model_ss.predict(X_train_ss)\n",
        "test_predictions_ss = lr_model_ss.predict(X_test_ss)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_ss = accuracy_score(y_train_ss, train_predictions_ss)\n",
        "test_accuracy_ss = accuracy_score(y_test_ss, test_predictions_ss)\n",
        "\n",
        "train_r2_ss = r2_score(y_train_ss, train_predictions_ss)\n",
        "test_r2_ss = r2_score(y_test_ss, test_predictions_ss)\n",
        "\n",
        "mae_value_ss = mean_absolute_error(y_test_ss, test_predictions_ss)\n",
        "mdse_value_ss = median_absolute_error(y_test_ss, test_predictions_ss)\n",
        "\n",
        "# Prepare results\n",
        "lr_results_ss = {\n",
        "    \"Accuracy (Train)\": train_accuracy_ss,\n",
        "    \"Accuracy (Test)\": test_accuracy_ss,\n",
        "    \"R Score (Train)\": train_r2_ss,\n",
        "    \"R Score (Test)\": test_r2_ss,\n",
        "    \"MAE\": mae_value_ss,\n",
        "    \"MdSE\": mdse_value_ss\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_ss = y_train_ss - train_predictions_ss\n",
        "test_residuals_ss = y_test_ss - test_predictions_ss\n",
        "\n",
        "lr_results_ss\n"
      ],
      "metadata": {
        "id": "FLs3qrxCECy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Logistic Regression (SS)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_ss, y=train_residuals_ss, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_ss, y=test_residuals_ss, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Logistic Regression (SS)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_ss, test_predictions_ss, label=f'$R^2$ = {test_r2_ss:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_ss), np.mean(test_predictions_ss)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Logistic Regression (SS)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xQ7K-SdzEFTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for SS\n",
        "data['Removal Efficiency SS'] = (data['In-SS\\n(mg/L)'] - data['Ef-SS\\n(mg/L)']) / data['In-SS\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Multiple Linear Regression\n",
        "features_ss_mlr = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                        'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                        'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_ss_mlr = data['Removal Efficiency SS']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_ss_mlr, X_test_ss_mlr, y_train_ss_mlr, y_test_ss_mlr = train_test_split(features_ss_mlr, target_ss_mlr, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Multiple Linear Regression model\n",
        "mlr_model_ss = LinearRegression()\n",
        "mlr_model_ss.fit(X_train_ss_mlr, y_train_ss_mlr)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_ss_mlr = mlr_model_ss.predict(X_train_ss_mlr)\n",
        "test_predictions_ss_mlr = mlr_model_ss.predict(X_test_ss_mlr)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_ss_mlr = np.mean(np.abs(y_train_ss_mlr - train_predictions_ss_mlr) <= tolerance)\n",
        "test_accuracy_ss_mlr = np.mean(np.abs(y_test_ss_mlr - test_predictions_ss_mlr) <= tolerance)\n",
        "\n",
        "train_r2_ss_mlr = r2_score(y_train_ss_mlr, train_predictions_ss_mlr)\n",
        "test_r2_ss_mlr = r2_score(y_test_ss_mlr, test_predictions_ss_mlr)\n",
        "\n",
        "mae_value_ss_mlr = mean_absolute_error(y_test_ss_mlr, test_predictions_ss_mlr)\n",
        "mdse_value_ss_mlr = median_absolute_error(y_test_ss_mlr, test_predictions_ss_mlr)\n",
        "\n",
        "# Prepare results\n",
        "mlr_results_ss = {\n",
        "    \"Accuracy (Train)\": train_accuracy_ss_mlr,\n",
        "    \"Accuracy (Test)\": test_accuracy_ss_mlr,\n",
        "    \"R Score (Train)\": train_r2_ss_mlr,\n",
        "    \"R Score (Test)\": test_r2_ss_mlr,\n",
        "    \"MAE\": mae_value_ss_mlr,\n",
        "    \"MdSE\": mdse_value_ss_mlr\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_ss_mlr = y_train_ss_mlr - train_predictions_ss_mlr\n",
        "test_residuals_ss_mlr = y_test_ss_mlr - test_predictions_ss_mlr\n",
        "\n",
        "mlr_results_ss\n"
      ],
      "metadata": {
        "id": "TFjzoFv0Ef8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Multiple Linear Regression (SS)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_ss_mlr, y=train_residuals_ss_mlr, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_ss_mlr, y=test_residuals_ss_mlr, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Multiple Linear Regression (SS)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_ss_mlr, test_predictions_ss_mlr, label=f'$R^2$ = {test_r2_ss_mlr:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_ss_mlr), np.mean(test_predictions_ss_mlr)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Multiple Linear Regression (SS)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Nuln9boHEiZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for SS\n",
        "data['Removal Efficiency SS'] = (data['In-SS\\n(mg/L)'] - data['Ef-SS\\n(mg/L)']) / data['In-SS\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Random Forest Regression\n",
        "features_ss_rf = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                       'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                       'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_ss_rf = data['Removal Efficiency SS']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_ss_rf, X_test_ss_rf, y_train_ss_rf, y_test_ss_rf = train_test_split(features_ss_rf, target_ss_rf, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Regression model\n",
        "rf_model_ss = RandomForestRegressor(random_state=42)\n",
        "rf_model_ss.fit(X_train_ss_rf, y_train_ss_rf)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_ss_rf = rf_model_ss.predict(X_train_ss_rf)\n",
        "test_predictions_ss_rf = rf_model_ss.predict(X_test_ss_rf)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_ss_rf = np.mean(np.abs(y_train_ss_rf - train_predictions_ss_rf) <= tolerance)\n",
        "test_accuracy_ss_rf = np.mean(np.abs(y_test_ss_rf - test_predictions_ss_rf) <= tolerance)\n",
        "\n",
        "train_r2_ss_rf = r2_score(y_train_ss_rf, train_predictions_ss_rf)\n",
        "test_r2_ss_rf = r2_score(y_test_ss_rf, test_predictions_ss_rf)\n",
        "\n",
        "mae_value_ss_rf = mean_absolute_error(y_test_ss_rf, test_predictions_ss_rf)\n",
        "mdse_value_ss_rf = median_absolute_error(y_test_ss_rf, test_predictions_ss_rf)\n",
        "\n",
        "# Prepare results\n",
        "rf_results_ss = {\n",
        "    \"Accuracy (Train)\": train_accuracy_ss_rf,\n",
        "    \"Accuracy (Test)\": test_accuracy_ss_rf,\n",
        "    \"R Score (Train)\": train_r2_ss_rf,\n",
        "    \"R Score (Test)\": test_r2_ss_rf,\n",
        "    \"MAE\": mae_value_ss_rf,\n",
        "    \"MdSE\": mdse_value_ss_rf\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_ss_rf = y_train_ss_rf - train_predictions_ss_rf\n",
        "test_residuals_ss_rf = y_test_ss_rf - test_predictions_ss_rf\n",
        "\n",
        "rf_results_ss\n"
      ],
      "metadata": {
        "id": "2TX9xAbQElwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Random Forest (SS)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_ss_rf, y=train_residuals_ss_rf, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_ss_rf, y=test_residuals_ss_rf, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Random Forest (SS)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_ss_rf, test_predictions_ss_rf, label=f'$R^2$ = {test_r2_ss_rf:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_ss_rf), np.mean(test_predictions_ss_rf)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Random Forest (SS)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LJ-bIZv3EoEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for SS\n",
        "data['Removal Efficiency SS'] = (data['In-SS\\n(mg/L)'] - data['Ef-SS\\n(mg/L)']) / data['In-SS\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Gradient Boosting Regression\n",
        "features_ss_gb = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                       'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                       'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_ss_gb = data['Removal Efficiency SS']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_ss_gb, X_test_ss_gb, y_train_ss_gb, y_test_ss_gb = train_test_split(features_ss_gb, target_ss_gb, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting Regression model\n",
        "gb_model_ss = GradientBoostingRegressor(random_state=42)\n",
        "gb_model_ss.fit(X_train_ss_gb, y_train_ss_gb)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_ss_gb = gb_model_ss.predict(X_train_ss_gb)\n",
        "test_predictions_ss_gb = gb_model_ss.predict(X_test_ss_gb)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_ss_gb = np.mean(np.abs(y_train_ss_gb - train_predictions_ss_gb) <= tolerance)\n",
        "test_accuracy_ss_gb = np.mean(np.abs(y_test_ss_gb - test_predictions_ss_gb) <= tolerance)\n",
        "\n",
        "train_r2_ss_gb = r2_score(y_train_ss_gb, train_predictions_ss_gb)\n",
        "test_r2_ss_gb = r2_score(y_test_ss_gb, test_predictions_ss_gb)\n",
        "\n",
        "mae_value_ss_gb = mean_absolute_error(y_test_ss_gb, test_predictions_ss_gb)\n",
        "mdse_value_ss_gb = median_absolute_error(y_test_ss_gb, test_predictions_ss_gb)\n",
        "\n",
        "# Prepare results\n",
        "gb_results_ss = {\n",
        "    \"Accuracy (Train)\": train_accuracy_ss_gb,\n",
        "    \"Accuracy (Test)\": test_accuracy_ss_gb,\n",
        "    \"R Score (Train)\": train_r2_ss_gb,\n",
        "    \"R Score (Test)\": test_r2_ss_gb,\n",
        "    \"MAE\": mae_value_ss_gb,\n",
        "    \"MdSE\": mdse_value_ss_gb\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_ss_gb = y_train_ss_gb - train_predictions_ss_gb\n",
        "test_residuals_ss_gb = y_test_ss_gb - test_predictions_ss_gb\n",
        "\n",
        "gb_results_ss\n"
      ],
      "metadata": {
        "id": "g5OSnhsKEqPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Gradient Boosting (SS)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_ss_gb, y=train_residuals_ss_gb, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_ss_gb, y=test_residuals_ss_gb, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Gradient Boosting (SS)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_ss_gb, test_predictions_ss_gb, label=f'$R^2$ = {test_r2_ss_gb:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_ss_gb), np.mean(test_predictions_ss_gb)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Gradient Boosting (SS)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qAX9bFx5Es7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for SS\n",
        "data['Removal Efficiency SS'] = (data['In-SS\\n(mg/L)'] - data['Ef-SS\\n(mg/L)']) / data['In-SS\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Support Vector Regression\n",
        "features_ss_svr = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                       'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                       'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_ss_svr = data['Removal Efficiency SS']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_ss_svr, X_test_ss_svr, y_train_ss_svr, y_test_ss_svr = train_test_split(features_ss_svr, target_ss_svr, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Support Vector Regression model\n",
        "svr_model_ss = SVR(kernel='rbf')\n",
        "svr_model_ss.fit(X_train_ss_svr, y_train_ss_svr)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_ss_svr = svr_model_ss.predict(X_train_ss_svr)\n",
        "test_predictions_ss_svr = svr_model_ss.predict(X_test_ss_svr)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_ss_svr = np.mean(np.abs(y_train_ss_svr - train_predictions_ss_svr) <= tolerance)\n",
        "test_accuracy_ss_svr = np.mean(np.abs(y_test_ss_svr - test_predictions_ss_svr) <= tolerance)\n",
        "\n",
        "train_r2_ss_svr = r2_score(y_train_ss_svr, train_predictions_ss_svr)\n",
        "test_r2_ss_svr = r2_score(y_test_ss_svr, test_predictions_ss_svr)\n",
        "\n",
        "mae_value_ss_svr = mean_absolute_error(y_test_ss_svr, test_predictions_ss_svr)\n",
        "mdse_value_ss_svr = median_absolute_error(y_test_ss_svr, test_predictions_ss_svr)\n",
        "\n",
        "# Prepare results\n",
        "svr_results_ss = {\n",
        "    \"Accuracy (Train)\": train_accuracy_ss_svr,\n",
        "    \"Accuracy (Test)\": test_accuracy_ss_svr,\n",
        "    \"R Score (Train)\": train_r2_ss_svr,\n",
        "    \"R Score (Test)\": test_r2_ss_svr,\n",
        "    \"MAE\": mae_value_ss_svr,\n",
        "    \"MdSE\": mdse_value_ss_svr\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_ss_svr = y_train_ss_svr - train_predictions_ss_svr\n",
        "test_residuals_ss_svr = y_test_ss_svr - test_predictions_ss_svr\n",
        "\n",
        "svr_results_ss\n"
      ],
      "metadata": {
        "id": "qthUfYULEvJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Support Vector Regression (SS)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_ss_svr, y=train_residuals_ss_svr, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_ss_svr, y=test_residuals_ss_svr, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Support Vector Regression (SS)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_ss_svr, test_predictions_ss_svr, label=f'$R^2$ = {test_r2_ss_svr:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_ss_svr), np.mean(test_predictions_ss_svr)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Support Vector Regression (SS)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xbasDvzaExpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare comparison data for multiple models on SS removal efficiency\n",
        "\n",
        "# Re-load the dataset\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for SS\n",
        "data['Removal Efficiency SS'] = (data['In-SS\\n(mg/L)'] - data['Ef-SS\\n(mg/L)']) / data['In-SS\\n(mg/L)']\n",
        "\n",
        "# Define features and target\n",
        "features_ss_all = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                        'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                        'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "target_ss_all = data['Removal Efficiency SS']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_ss_all, X_test_ss_all, y_train_ss_all, y_test_ss_all = train_test_split(features_ss_all, target_ss_all, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define models for comparison\n",
        "models_ss = {\n",
        "    \"Multiple Linear Regression\": LinearRegression(),\n",
        "    \"Support Vector Regression\": SVR(kernel='rbf'),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results_ss_all = []\n",
        "\n",
        "for model_name, model in models_ss.items():\n",
        "    model.fit(X_train_ss_all, y_train_ss_all)\n",
        "    train_preds_all = model.predict(X_train_ss_all)\n",
        "    test_preds_all = model.predict(X_test_ss_all)\n",
        "\n",
        "    train_r2_all = r2_score(y_train_ss_all, train_preds_all)\n",
        "    test_r2_all = r2_score(y_test_ss_all, test_preds_all)\n",
        "    mae_all = mean_absolute_error(y_test_ss_all, test_preds_all)\n",
        "    mdse_all = median_absolute_error(y_test_ss_all, test_preds_all)\n",
        "    train_acc_all = np.mean(np.abs(y_train_ss_all - train_preds_all) <= tolerance)\n",
        "    test_acc_all = np.mean(np.abs(y_test_ss_all - test_preds_all) <= tolerance)\n",
        "\n",
        "    results_ss_all.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Train R\": train_r2_all,\n",
        "        \"Test R\": test_r2_all,\n",
        "        \"MAE\": mae_all,\n",
        "        \"MdSE\": mdse_all,\n",
        "        \"Train Accuracy\": train_acc_all,\n",
        "        \"Test Accuracy\": test_acc_all\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame for visualization\n",
        "results_ss_df = pd.DataFrame(results_ss_all)\n",
        "\n",
        "# Display the results\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Model Comparison for SS Removal Efficiency\", dataframe=results_ss_df)\n"
      ],
      "metadata": {
        "id": "IV3t1bhHE1Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual comparison including R Scores, MAE, and Accuracy for SS removal efficiency\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "\n",
        "# Subplot 1: Comparison of R Scores by Models\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(data=results_ss_df, x='Model', y='Test R', palette='viridis')\n",
        "plt.title('Comparison Of R Scores By Models for SS')\n",
        "plt.ylabel('R Score')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 2: Comparison of Mean Absolute Error (MAE) by Models\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(data=results_ss_df, x='Model', y='MAE', palette='viridis')\n",
        "plt.title('Comparison of Mean Absolute Error (MAE) by Models for SS')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 3: Comparison Of Accuracy By Models\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(data=results_ss_df, x='Model', y='Test Accuracy', palette='viridis')\n",
        "plt.title('Comparison Of Accuracy By Models for SS')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(rotation=15)\n",
        "plt.ylim(0.9, 1.05)  # Zooming in to better visualize the differences\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jHVfmCiXE3QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Create a binary target variable for logistic regression, similar to previous approach\n",
        "threshold_bod = data['Removal Efficiency BOD'].median()\n",
        "data['High Removal BOD'] = (data['Removal Efficiency BOD'] >= threshold_bod).astype(int)\n",
        "\n",
        "# Define features and target for logistic regression\n",
        "features_bod = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                     'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                     'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_bod = data['High Removal BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_bod, X_test_bod, y_train_bod, y_test_bod = train_test_split(features_bod, target_bod, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model_bod = LogisticRegression(max_iter=1000)\n",
        "lr_model_bod.fit(X_train_bod, y_train_bod)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_bod = lr_model_bod.predict(X_train_bod)\n",
        "test_predictions_bod = lr_model_bod.predict(X_test_bod)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_bod = accuracy_score(y_train_bod, train_predictions_bod)\n",
        "test_accuracy_bod = accuracy_score(y_test_bod, test_predictions_bod)\n",
        "\n",
        "train_r2_bod = r2_score(y_train_bod, train_predictions_bod)\n",
        "test_r2_bod = r2_score(y_test_bod, test_predictions_bod)\n",
        "\n",
        "mae_value_bod = mean_absolute_error(y_test_bod, test_predictions_bod)\n",
        "mdse_value_bod = median_absolute_error(y_test_bod, test_predictions_bod)\n",
        "\n",
        "# Prepare results\n",
        "lr_results_bod = {\n",
        "    \"Accuracy (Train)\": train_accuracy_bod,\n",
        "    \"Accuracy (Test)\": test_accuracy_bod,\n",
        "    \"R Score (Train)\": train_r2_bod,\n",
        "    \"R Score (Test)\": test_r2_bod,\n",
        "    \"MAE\": mae_value_bod,\n",
        "    \"MdSE\": mdse_value_bod\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_bod = y_train_bod - train_predictions_bod\n",
        "test_residuals_bod = y_test_bod - test_predictions_bod\n",
        "\n",
        "lr_results_bod\n"
      ],
      "metadata": {
        "id": "BoqmnrFCE5Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Logistic Regression (BOD)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_bod, y=train_residuals_bod, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_bod, y=test_residuals_bod, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Logistic Regression (BOD)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_bod, test_predictions_bod, label=f'$R^2$ = {test_r2_bod:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_bod), np.mean(test_predictions_bod)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Logistic Regression (BOD)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CVJmBzVgE7C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Multiple Linear Regression\n",
        "features_bod_mlr = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                         'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                         'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_bod_mlr = data['Removal Efficiency BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_bod_mlr, X_test_bod_mlr, y_train_bod_mlr, y_test_bod_mlr = train_test_split(features_bod_mlr, target_bod_mlr, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Multiple Linear Regression model\n",
        "mlr_model_bod = LinearRegression()\n",
        "mlr_model_bod.fit(X_train_bod_mlr, y_train_bod_mlr)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_bod_mlr = mlr_model_bod.predict(X_train_bod_mlr)\n",
        "test_predictions_bod_mlr = mlr_model_bod.predict(X_test_bod_mlr)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_bod_mlr = np.mean(np.abs(y_train_bod_mlr - train_predictions_bod_mlr) <= tolerance)\n",
        "test_accuracy_bod_mlr = np.mean(np.abs(y_test_bod_mlr - test_predictions_bod_mlr) <= tolerance)\n",
        "\n",
        "train_r2_bod_mlr = r2_score(y_train_bod_mlr, train_predictions_bod_mlr)\n",
        "test_r2_bod_mlr = r2_score(y_test_bod_mlr, test_predictions_bod_mlr)\n",
        "\n",
        "mae_value_bod_mlr = mean_absolute_error(y_test_bod_mlr, test_predictions_bod_mlr)\n",
        "mdse_value_bod_mlr = median_absolute_error(y_test_bod_mlr, test_predictions_bod_mlr)\n",
        "\n",
        "# Prepare results\n",
        "mlr_results_bod = {\n",
        "    \"Accuracy (Train)\": train_accuracy_bod_mlr,\n",
        "    \"Accuracy (Test)\": test_accuracy_bod_mlr,\n",
        "    \"R Score (Train)\": train_r2_bod_mlr,\n",
        "    \"R Score (Test)\": test_r2_bod_mlr,\n",
        "    \"MAE\": mae_value_bod_mlr,\n",
        "    \"MdSE\": mdse_value_bod_mlr\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_bod_mlr = y_train_bod_mlr - train_predictions_bod_mlr\n",
        "test_residuals_bod_mlr = y_test_bod_mlr - test_predictions_bod_mlr\n",
        "\n",
        "mlr_results_bod\n"
      ],
      "metadata": {
        "id": "qZ3ODFFvE87o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Multiple Linear Regression (BOD)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_bod_mlr, y=train_residuals_bod_mlr, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_bod_mlr, y=test_residuals_bod_mlr, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Multiple Linear Regression (BOD)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_bod_mlr, test_predictions_bod_mlr, label=f'$R^2$ = {test_r2_bod_mlr:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_bod_mlr), np.mean(test_predictions_bod_mlr)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Multiple Linear Regression (BOD)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jB_cBjymFAFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Random Forest Regression\n",
        "features_bod_rf = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                        'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                        'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_bod_rf = data['Removal Efficiency BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_bod_rf, X_test_bod_rf, y_train_bod_rf, y_test_bod_rf = train_test_split(features_bod_rf, target_bod_rf, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Regression model\n",
        "rf_model_bod = RandomForestRegressor(random_state=42)\n",
        "rf_model_bod.fit(X_train_bod_rf, y_train_bod_rf)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_bod_rf = rf_model_bod.predict(X_train_bod_rf)\n",
        "test_predictions_bod_rf = rf_model_bod.predict(X_test_bod_rf)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_bod_rf = np.mean(np.abs(y_train_bod_rf - train_predictions_bod_rf) <= tolerance)\n",
        "test_accuracy_bod_rf = np.mean(np.abs(y_test_bod_rf - test_predictions_bod_rf) <= tolerance)\n",
        "\n",
        "train_r2_bod_rf = r2_score(y_train_bod_rf, train_predictions_bod_rf)\n",
        "test_r2_bod_rf = r2_score(y_test_bod_rf, test_predictions_bod_rf)\n",
        "\n",
        "mae_value_bod_rf = mean_absolute_error(y_test_bod_rf, test_predictions_bod_rf)\n",
        "mdse_value_bod_rf = median_absolute_error(y_test_bod_rf, test_predictions_bod_rf)\n",
        "\n",
        "# Prepare results\n",
        "rf_results_bod = {\n",
        "    \"Accuracy (Train)\": train_accuracy_bod_rf,\n",
        "    \"Accuracy (Test)\": test_accuracy_bod_rf,\n",
        "    \"R Score (Train)\": train_r2_bod_rf,\n",
        "    \"R Score (Test)\": test_r2_bod_rf,\n",
        "    \"MAE\": mae_value_bod_rf,\n",
        "    \"MdSE\": mdse_value_bod_rf\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_bod_rf = y_train_bod_rf - train_predictions_bod_rf\n",
        "test_residuals_bod_rf = y_test_bod_rf - test_predictions_bod_rf\n",
        "\n",
        "rf_results_bod\n"
      ],
      "metadata": {
        "id": "b2mwsu5oFCLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Random Forest (BOD)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_bod_rf, y=train_residuals_bod_rf, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_bod_rf, y=test_residuals_bod_rf, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Random Forest (BOD)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_bod_rf, test_predictions_bod_rf, label=f'$R^2$ = {test_r2_bod_rf:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_bod_rf), np.mean(test_predictions_bod_rf)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Random Forest (BOD)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4wZXTp2IFEfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Gradient Boosting Regression\n",
        "features_bod_gb = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                        'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                        'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_bod_gb = data['Removal Efficiency BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_bod_gb, X_test_bod_gb, y_train_bod_gb, y_test_bod_gb = train_test_split(features_bod_gb, target_bod_gb, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting Regression model\n",
        "gb_model_bod = GradientBoostingRegressor(random_state=42)\n",
        "gb_model_bod.fit(X_train_bod_gb, y_train_bod_gb)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_bod_gb = gb_model_bod.predict(X_train_bod_gb)\n",
        "test_predictions_bod_gb = gb_model_bod.predict(X_test_bod_gb)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_bod_gb = np.mean(np.abs(y_train_bod_gb - train_predictions_bod_gb) <= tolerance)\n",
        "test_accuracy_bod_gb = np.mean(np.abs(y_test_bod_gb - test_predictions_bod_gb) <= tolerance)\n",
        "\n",
        "train_r2_bod_gb = r2_score(y_train_bod_gb, train_predictions_bod_gb)\n",
        "test_r2_bod_gb = r2_score(y_test_bod_gb, test_predictions_bod_gb)\n",
        "\n",
        "mae_value_bod_gb = mean_absolute_error(y_test_bod_gb, test_predictions_bod_gb)\n",
        "mdse_value_bod_gb = median_absolute_error(y_test_bod_gb, test_predictions_bod_gb)\n",
        "\n",
        "# Prepare results\n",
        "gb_results_bod = {\n",
        "    \"Accuracy (Train)\": train_accuracy_bod_gb,\n",
        "    \"Accuracy (Test)\": test_accuracy_bod_gb,\n",
        "    \"R Score (Train)\": train_r2_bod_gb,\n",
        "    \"R Score (Test)\": test_r2_bod_gb,\n",
        "    \"MAE\": mae_value_bod_gb,\n",
        "    \"MdSE\": mdse_value_bod_gb\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_bod_gb = y_train_bod_gb - train_predictions_bod_gb\n",
        "test_residuals_bod_gb = y_test_bod_gb - test_predictions_bod_gb\n",
        "\n",
        "gb_results_bod\n"
      ],
      "metadata": {
        "id": "IRfgsq-DFGZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Gradient Boosting (BOD)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_bod_gb, y=train_residuals_bod_gb, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_bod_gb, y=test_residuals_bod_gb, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Gradient Boosting (BOD)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_bod_gb, test_predictions_bod_gb, label=f'$R^2$ = {test_r2_bod_gb:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_bod_gb), np.mean(test_predictions_bod_gb)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Gradient Boosting (BOD)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1glUO8NhFIoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import the dataset to ensure we are using the latest version\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Define features and target for Support Vector Regression\n",
        "features_bod_svr = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                        'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                        'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "\n",
        "target_bod_svr = data['Removal Efficiency BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_bod_svr, X_test_bod_svr, y_train_bod_svr, y_test_bod_svr = train_test_split(features_bod_svr, target_bod_svr, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Support Vector Regression model\n",
        "svr_model_bod = SVR(kernel='rbf')\n",
        "svr_model_bod.fit(X_train_bod_svr, y_train_bod_svr)\n",
        "\n",
        "# Predict on training and testing sets\n",
        "train_predictions_bod_svr = svr_model_bod.predict(X_train_bod_svr)\n",
        "test_predictions_bod_svr = svr_model_bod.predict(X_test_bod_svr)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy_bod_svr = np.mean(np.abs(y_train_bod_svr - train_predictions_bod_svr) <= tolerance)\n",
        "test_accuracy_bod_svr = np.mean(np.abs(y_test_bod_svr - test_predictions_bod_svr) <= tolerance)\n",
        "\n",
        "train_r2_bod_svr = r2_score(y_train_bod_svr, train_predictions_bod_svr)\n",
        "test_r2_bod_svr = r2_score(y_test_bod_svr, test_predictions_bod_svr)\n",
        "\n",
        "mae_value_bod_svr = mean_absolute_error(y_test_bod_svr, test_predictions_bod_svr)\n",
        "mdse_value_bod_svr = median_absolute_error(y_test_bod_svr, test_predictions_bod_svr)\n",
        "\n",
        "# Prepare results\n",
        "svr_results_bod = {\n",
        "    \"Accuracy (Train)\": train_accuracy_bod_svr,\n",
        "    \"Accuracy (Test)\": test_accuracy_bod_svr,\n",
        "    \"R Score (Train)\": train_r2_bod_svr,\n",
        "    \"R Score (Test)\": test_r2_bod_svr,\n",
        "    \"MAE\": mae_value_bod_svr,\n",
        "    \"MdSE\": mdse_value_bod_svr\n",
        "}\n",
        "\n",
        "# Prepare data for plotting\n",
        "train_residuals_bod_svr = y_train_bod_svr - train_predictions_bod_svr\n",
        "test_residuals_bod_svr = y_test_bod_svr - test_predictions_bod_svr\n",
        "\n",
        "svr_results_bod\n"
      ],
      "metadata": {
        "id": "s9mkN8-gFKxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals vs Predicted Value and Prediction Error Plot for Support Vector Regression (BOD)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Residuals vs Predicted Value Plot\n",
        "sns.scatterplot(x=train_predictions_bod_svr, y=train_residuals_bod_svr, color=\"blue\", label='Train Residuals', ax=ax1)\n",
        "sns.scatterplot(x=test_predictions_bod_svr, y=test_residuals_bod_svr, color=\"green\", label='Test Residuals', ax=ax1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--')\n",
        "ax1.set_xlabel('Predicted Value')\n",
        "ax1.set_ylabel('Residuals')\n",
        "ax1.set_title('Residuals vs Predicted Value for Support Vector Regression (BOD)')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Prediction Error Plot\n",
        "ax2.scatter(y_test_bod_svr, test_predictions_bod_svr, label=f'$R^2$ = {test_r2_bod_svr:.3f}', alpha=0.7, edgecolors='b')\n",
        "ax2.plot([0, 1], [0, 1], '--', color='black', label='identity')\n",
        "ax2.plot([0, 1], [np.mean(test_predictions_bod_svr), np.mean(test_predictions_bod_svr)], '--', color='gray', label='best fit')\n",
        "ax2.set_xlabel('$y$')\n",
        "ax2.set_ylabel('$\\hat{y}$')\n",
        "ax2.set_title('Prediction Error for Support Vector Regression (BOD)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hIj7hPtPFNKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare comparison data for multiple models on BOD removal efficiency\n",
        "\n",
        "# Re-load the dataset\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "\n",
        "# Define features and target\n",
        "features_bod_all = data[['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "                         'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "                         'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']]\n",
        "target_bod_all = data['Removal Efficiency BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_bod_all, X_test_bod_all, y_train_bod_all, y_test_bod_all = train_test_split(features_bod_all, target_bod_all, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define models for comparison\n",
        "models_bod = {\n",
        "    \"Multiple Linear Regression\": LinearRegression(),\n",
        "    \"Support Vector Regression\": SVR(kernel='rbf'),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results_bod_all = []\n",
        "\n",
        "for model_name, model in models_bod.items():\n",
        "    model.fit(X_train_bod_all, y_train_bod_all)\n",
        "    train_preds_all = model.predict(X_train_bod_all)\n",
        "    test_preds_all = model.predict(X_test_bod_all)\n",
        "\n",
        "    train_r2_all = r2_score(y_train_bod_all, train_preds_all)\n",
        "    test_r2_all = r2_score(y_test_bod_all, test_preds_all)\n",
        "    mae_all = mean_absolute_error(y_test_bod_all, test_preds_all)\n",
        "    mdse_all = median_absolute_error(y_test_bod_all, test_preds_all)\n",
        "    train_acc_all = np.mean(np.abs(y_train_bod_all - train_preds_all) <= tolerance)\n",
        "    test_acc_all = np.mean(np.abs(y_test_bod_all - test_preds_all) <= tolerance)\n",
        "\n",
        "    results_bod_all.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Train R\": train_r2_all,\n",
        "        \"Test R\": test_r2_all,\n",
        "        \"MAE\": mae_all,\n",
        "        \"MdSE\": mdse_all,\n",
        "        \"Train Accuracy\": train_acc_all,\n",
        "        \"Test Accuracy\": test_acc_all\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame for visualization\n",
        "results_bod_df = pd.DataFrame(results_bod_all)\n",
        "\n",
        "# Display the results\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Model Comparison for BOD Removal Efficiency\", dataframe=results_bod_df)\n"
      ],
      "metadata": {
        "id": "2NoDWY4HFP6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual comparison including R Scores, MAE, and Accuracy for BOD removal efficiency\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "\n",
        "# Subplot 1: Comparison of R Scores by Models\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(data=results_bod_df, x='Model', y='Test R', palette='viridis')\n",
        "plt.title('Comparison Of R Scores By Models for BOD')\n",
        "plt.ylabel('R Score')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 2: Comparison of Mean Absolute Error (MAE) by Models\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.barplot(data=results_bod_df, x='Model', y='MAE', palette='viridis')\n",
        "plt.title('Comparison of Mean Absolute Error (MAE) by Models for BOD')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 3: Comparison Of Accuracy By Models\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.barplot(data=results_bod_df, x='Model', y='Test Accuracy', palette='viridis')\n",
        "plt.title('Comparison Of Accuracy By Models for BOD')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(rotation=15)\n",
        "plt.ylim(0.9, 1.05)  # Zooming in to better visualize the differences\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R6BTOdtGFSCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Binarize the target variable for ROC curve analysis (using the median as threshold)\n",
        "threshold_bod = data['Removal Efficiency BOD'].median()\n",
        "data['High Removal BOD'] = (data['Removal Efficiency BOD'] >= threshold_bod).astype(int)\n",
        "\n",
        "# Define the new binary target\n",
        "target_bod_binary = data['High Removal BOD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_bod_bin, X_test_bod_bin, y_train_bod_bin, y_test_bod_bin = train_test_split(features_bod_all, target_bod_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the models with binary target and predict probabilities\n",
        "model_predictions = {}\n",
        "for model_name, model in models_bod.items():\n",
        "    model.fit(X_train_bod_bin, y_train_bod_bin)\n",
        "    prob_predictions = model.predict_proba(X_test_bod_bin)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_test_bod_bin)\n",
        "    fpr, tpr, _ = roc_curve(y_test_bod_bin, prob_predictions)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    model_predictions[model_name] = (fpr, tpr, roc_auc)\n",
        "\n",
        "# Plot ROC curves for all models\n",
        "plt.figure(figsize=(10, 8))\n",
        "for model_name, (fpr, tpr, roc_auc) in model_predictions.items():\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for BOD Removal Efficiency Prediction Models')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ibkTMLeSFXRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Removal Efficiency for COD and binarize the target variable\n",
        "data['Removal Efficiency COD'] = (data['In-CODcr\\n(mg/L)'] - data['Ef-CODcr\\n(mg/L)']) / data['In-CODcr\\n(mg/L)']\n",
        "threshold_cod = data['Removal Efficiency COD'].median()\n",
        "data['High Removal COD'] = (data['Removal Efficiency COD'] >= threshold_cod).astype(int)\n",
        "\n",
        "# Define the new binary target for COD\n",
        "target_cod_binary = data['High Removal COD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_cod_bin, X_test_cod_bin, y_train_cod_bin, y_test_cod_bin = train_test_split(features_bod_all, target_cod_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the models with binary target for COD and predict probabilities\n",
        "model_predictions_cod = {}\n",
        "for model_name, model in models_bod.items():\n",
        "    model.fit(X_train_cod_bin, y_train_cod_bin)\n",
        "    prob_predictions_cod = model.predict_proba(X_test_cod_bin)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_test_cod_bin)\n",
        "    fpr, tpr, _ = roc_curve(y_test_cod_bin, prob_predictions_cod)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    model_predictions_cod[model_name] = (fpr, tpr, roc_auc)\n",
        "\n",
        "# Plot ROC curves for all models (COD)\n",
        "plt.figure(figsize=(10, 8))\n",
        "for model_name, (fpr, tpr, roc_auc) in model_predictions_cod.items():\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for COD Removal Efficiency Prediction Models')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7FezhsWSFaIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Removal Efficiency for SS and binarize the target variable\n",
        "data['Removal Efficiency SS'] = (data['In-SS\\n(mg/L)'] - data['Ef-SS\\n(mg/L)']) / data['In-SS\\n(mg/L)']\n",
        "threshold_ss = data['Removal Efficiency SS'].median()\n",
        "data['High Removal SS'] = (data['Removal Efficiency SS'] >= threshold_ss).astype(int)\n",
        "\n",
        "# Define the new binary target for SS\n",
        "target_ss_binary = data['High Removal SS']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_ss_bin, X_test_ss_bin, y_train_ss_bin, y_test_ss_bin = train_test_split(features_bod_all, target_ss_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the models with binary target for SS and predict probabilities\n",
        "model_predictions_ss = {}\n",
        "for model_name, model in models_bod.items():\n",
        "    model.fit(X_train_ss_bin, y_train_ss_bin)\n",
        "    prob_predictions_ss = model.predict_proba(X_test_ss_bin)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_test_ss_bin)\n",
        "    fpr, tpr, _ = roc_curve(y_test_ss_bin, prob_predictions_ss)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    model_predictions_ss[model_name] = (fpr, tpr, roc_auc)\n",
        "\n",
        "# Plot ROC curves for all models (SS)\n",
        "plt.figure(figsize=(10, 8))\n",
        "for model_name, (fpr, tpr, roc_auc) in model_predictions_ss.items():\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for SS Removal Efficiency Prediction Models')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1w6ZraOcFcLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset again\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Features to consider for sensitivity analysis\n",
        "features = ['In-pH', 'Ef-pH', 'In-CODcr\\n(mg/L)', 'Ef-CODcr\\n(mg/L)',\n",
        "            'In-Ammonia-N\\n(mg/L)', 'Ef-Ammonia-N\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "            'Ef-SS\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'Ef-Phosphate\\n(mg/L)']\n",
        "\n",
        "# Mapping for more readable feature names\n",
        "feature_names = ['In-pH', 'Ef-pH', 'In-COD', 'Ef-COD',\n",
        "                 'In-Ammonia-N', 'Ef-Ammonia-N', 'In-SS',\n",
        "                 'Ef-SS', 'In-Phosphate', 'Ef-Phosphate']\n",
        "\n",
        "# Target variables\n",
        "targets = {\n",
        "    'BOD': (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)'],\n",
        "    'COD': (data['In-CODcr\\n(mg/L)'] - data['Ef-CODcr\\n(mg/L)']) / data['In-CODcr\\n(mg/L)'],\n",
        "    'SS': (data['In-SS\\n(mg/L)'] - data['Ef-SS\\n(mg/L)']) / data['In-SS\\n(mg/L)']\n",
        "}\n",
        "\n",
        "# Feature importance dictionary\n",
        "feature_importances = {}\n",
        "\n",
        "# Calculate feature importance for each target using Random Forest\n",
        "for target_name, target_values in targets.items():\n",
        "    X = data[features]\n",
        "    y = target_values\n",
        "    rf_model = RandomForestRegressor(random_state=42)\n",
        "    rf_model.fit(X, y)\n",
        "    feature_importances[target_name] = rf_model.feature_importances_\n",
        "\n",
        "# Plot the sensitivity analysis for each target\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Subplot (a) for SS\n",
        "axs[0].bar(feature_names, feature_importances['SS'], color='blue')\n",
        "axs[0].set_title('Sensitivity Analysis of Input Variables on RF Modeling (a) SS')\n",
        "axs[0].set_xlabel('Predictor variable')\n",
        "axs[0].set_ylabel('Importance')\n",
        "axs[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Subplot (b) for COD\n",
        "axs[1].bar(feature_names, feature_importances['COD'], color='blue')\n",
        "axs[1].set_title('Sensitivity Analysis of Input Variables on RF Modeling (b) COD')\n",
        "axs[1].set_xlabel('Predictor variable')\n",
        "axs[1].set_ylabel('Importance')\n",
        "axs[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Subplot (c) for BOD\n",
        "axs[2].bar(feature_names, feature_importances['BOD'], color='blue')\n",
        "axs[2].set_title('Sensitivity Analysis of Input Variables on RF Modeling (c) BOD')\n",
        "axs[2].set_xlabel('Predictor variable')\n",
        "axs[2].set_ylabel('Importance')\n",
        "axs[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pAJknDKQFeu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset again\n",
        "data = pd.read_excel('/mnt/data/DSTP Data.xlsx')\n",
        "\n",
        "# Calculate Removal Efficiency for BOD, COD, and SS\n",
        "data['Removal Efficiency BOD'] = (data['In-BOD\\n(mg/L)'] - data['Ef-BOD\\n(mg/L)']) / data['In-BOD\\n(mg/L)']\n",
        "data['Removal Efficiency COD'] = (data['In-CODcr\\n(mg/L)'] - data['Ef-CODcr\\n(mg/L)']) / data['In-CODcr\\n(mg/L)']\n",
        "data['Removal Efficiency SS'] = (data['In-SS\\n(mg/L)'] - data['Ef-SS\\n(mg/L)']) / data['In-SS\\n(mg/L)']\n",
        "\n",
        "# Features to consider for sensitivity analysis\n",
        "features = ['In-pH', 'In-CODcr\\n(mg/L)', 'In-BOD\\n(mg/L)', 'In-SS\\n(mg/L)',\n",
        "            'In-Ammonia-N\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'In-TOC\\n(mg/L)',\n",
        "            'In-Nitrate-N\\n(mg/L)', 'In-Phosphate\\n(mg/L)', 'In-TDS\\n(mg/L)']\n",
        "\n",
        "# Rename features for readability\n",
        "feature_names = ['pH', 'COD', 'BOD', 'SS', 'NH3-N', 'PO4', 'TOC', 'NO3-N', 'PO4', 'TDS']\n",
        "\n",
        "# Target variables\n",
        "targets = {\n",
        "    'BOD': data['Removal Efficiency BOD'],\n",
        "    'COD': data['Removal Efficiency COD'],\n",
        "    'SS': data['Removal Efficiency SS']\n",
        "}\n",
        "\n",
        "# Feature importance dictionary\n",
        "feature_importances = {}\n",
        "\n",
        "# Calculate feature importance for each target using Random Forest\n",
        "for target_name, target_values in targets.items():\n",
        "    X = data[features]\n",
        "    y = target_values\n",
        "    rf_model = RandomForestRegressor(random_state=42)\n",
        "    rf_model.fit(X, y)\n",
        "    feature_importances[target_name] = rf_model.feature_importances_\n",
        "\n",
        "# Plot the sensitivity analysis for each target in separate bar plots\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot for SS\n",
        "plt.bar(feature_names, feature_importances['SS'], color='blue')\n",
        "plt.title('Sensitivity Analysis of Input Variables on RF Modeling (SS)')\n",
        "plt.xlabel('Predictor variable')\n",
        "plt.ylabel('Importance')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot for COD\n",
        "plt.bar(feature_names, feature_importances['COD'], color='blue')\n",
        "plt.title('Sensitivity Analysis of Input Variables on RF Modeling (COD)')\n",
        "plt.xlabel('Predictor variable')\n",
        "plt.ylabel('Importance')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot for BOD\n",
        "plt.bar(feature_names, feature_importances['BOD'], color='blue')\n",
        "plt.title('Sensitivity Analysis of Input Variables on RF Modeling (BOD)')\n",
        "plt.xlabel('Predictor variable')\n",
        "plt.ylabel('Importance')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bO5sFuiAFlOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusting features to include only existing columns in the dataset\n",
        "existing_features = [col for col in features if col in data.columns]\n",
        "\n",
        "# Updating feature names accordingly\n",
        "existing_feature_names = [feature_names[features.index(col)] for col in existing_features]\n",
        "\n",
        "# Calculate feature importance for each target using Random Forest\n",
        "feature_importances_adjusted = {}\n",
        "\n",
        "for target_name, target_values in targets.items():\n",
        "    X = data[existing_features]\n",
        "    y = target_values\n",
        "    rf_model = RandomForestRegressor(random_state=42)\n",
        "    rf_model.fit(X, y)\n",
        "    feature_importances_adjusted[target_name] = rf_model.feature_importances_\n",
        "\n",
        "# Plot the sensitivity analysis for each target in separate bar plots\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot for SS\n",
        "plt.bar(existing_feature_names, feature_importances_adjusted['SS'], color='blue')\n",
        "plt.title('Sensitivity Analysis of Input Variables on RF Modeling (SS)')\n",
        "plt.xlabel('Predictor variable')\n",
        "plt.ylabel('Importance')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot for COD\n",
        "plt.bar(existing_feature_names, feature_importances_adjusted['COD'], color='blue')\n",
        "plt.title('Sensitivity Analysis of Input Variables on RF Modeling (COD)')\n",
        "plt.xlabel('Predictor variable')\n",
        "plt.ylabel('Importance')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot for BOD\n",
        "plt.bar(existing_feature_names, feature_importances_adjusted['BOD'], color='blue')\n",
        "plt.title('Sensitivity Analysis of Input Variables on RF Modeling (BOD)')\n",
        "plt.xlabel('Predictor variable')\n",
        "plt.ylabel('Importance')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5gpZKw1OFniF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define targets and feature sets for SS, COD, and BOD removal efficiency\n",
        "targets_removal = {\n",
        "    'SS': data['Removal Efficiency SS'],\n",
        "    'COD': data['Removal Efficiency COD'],\n",
        "    'BOD': data['Removal Efficiency BOD']\n",
        "}\n",
        "\n",
        "# Results dictionary for storing the model performance metrics\n",
        "results_removal_all = []\n",
        "\n",
        "# Models to be evaluated\n",
        "models_removal = {\n",
        "    \"Multiple Linear Regression\": LinearRegression(),\n",
        "    \"Support Vector Regression\": SVR(kernel='rbf'),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# Evaluate each model for each target\n",
        "for target_name, target_values in targets_removal.items():\n",
        "    X = data[existing_features]  # Use existing features adjusted earlier\n",
        "    y = target_values\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    for model_name, model in models_removal.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        train_preds = model.predict(X_train)\n",
        "        test_preds = model.predict(X_test)\n",
        "\n",
        "        train_r2 = r2_score(y_train, train_preds)\n",
        "        test_r2 = r2_score(y_test, test_preds)\n",
        "        mae = mean_absolute_error(y_test, test_preds)\n",
        "        mdse = median_absolute_error(y_test, test_preds)\n",
        "        train_acc = np.mean(np.abs(y_train - train_preds) <= tolerance)\n",
        "        test_acc = np.mean(np.abs(y_test - test_preds) <= tolerance)\n",
        "\n",
        "        results_removal_all.append({\n",
        "            \"Target\": target_name,\n",
        "            \"Model\": model_name,\n",
        "            \"Train R\": train_r2,\n",
        "            \"Test R\": test_r2,\n",
        "            \"MAE\": mae,\n",
        "            \"MdSE\": mdse,\n",
        "            \"Train Accuracy\": train_acc,\n",
        "            \"Test Accuracy\": test_acc\n",
        "        })\n",
        "\n",
        "# Convert results to a DataFrame for visualization\n",
        "results_removal_df = pd.DataFrame(results_removal_all)\n",
        "\n",
        "# Display the results\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Model Assessment for SS, COD, and BOD Removal Efficiency\", dataframe=results_removal_df)\n"
      ],
      "metadata": {
        "id": "IJxFoNmaFqsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine feature importances for all targets\n",
        "combined_feature_importance = np.zeros(len(existing_features))\n",
        "\n",
        "# Sum the feature importances for each target\n",
        "for target in feature_importances_adjusted.values():\n",
        "    combined_feature_importance += target\n",
        "\n",
        "# Create a DataFrame for easier interpretation\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': existing_feature_names,\n",
        "    'Combined Importance': combined_feature_importance\n",
        "})\n",
        "\n",
        "# Sort features by combined importance\n",
        "sorted_feature_importance_df = feature_importance_df.sort_values(by='Combined Importance', ascending=False)\n",
        "\n",
        "# Display the sorted feature importance\n",
        "tools.display_dataframe_to_user(name=\"Overall Best Features Based on Combined Importance\", dataframe=sorted_feature_importance_df)\n"
      ],
      "metadata": {
        "id": "uFFiSCf5FtSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best model selection based on highest Test R score for each target\n",
        "best_models_summary = []\n",
        "\n",
        "for target_name in ['SS', 'COD', 'BOD']:\n",
        "    # Filter the results for the specific target\n",
        "    target_results = results_removal_df[results_removal_df['Target'] == target_name]\n",
        "    # Select the model with the highest Test R score\n",
        "    best_model = target_results.loc[target_results['Test R'].idxmax()]\n",
        "    best_models_summary.append(best_model)\n",
        "\n",
        "# Convert the summary of best models into a DataFrame\n",
        "best_models_df = pd.DataFrame(best_models_summary)\n",
        "\n",
        "# Display the results\n",
        "tools.display_dataframe_to_user(name=\"Best Model Comparison for SS, COD, and BOD Removal Efficiency\", dataframe=best_models_df)\n"
      ],
      "metadata": {
        "id": "3Szq_XhFFxU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual comparison for the best models of SS, COD, and BOD Removal Efficiency\n",
        "\n",
        "plt.figure(figsize=(18, 8))\n",
        "\n",
        "# Subplot 1: Test R Scores Comparison\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.barplot(data=best_models_df, x='Target', y='Test R', hue='Model', palette='viridis')\n",
        "plt.title('Comparison of Test R Scores for Best Models')\n",
        "plt.ylabel('Test R')\n",
        "plt.ylim(0, 1)  # Set y-limit to emphasize differences\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 2: Mean Absolute Error (MAE) Comparison\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.barplot(data=best_models_df, x='Target', y='MAE', hue='Model', palette='viridis')\n",
        "plt.title('Comparison of Mean Absolute Error (MAE) for Best Models')\n",
        "plt.ylabel('MAE')\n",
        "plt.grid(True)\n",
        "\n",
        "# Subplot 3: Accuracy Comparison\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.barplot(data=best_models_df, x='Target', y='Test Accuracy', hue='Model', palette='viridis')\n",
        "plt.title('Comparison of Test Accuracy for Best Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0.9, 1.05)  # Zooming in to better visualize the differences\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HWtwhM1kFzpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LKWW_JH-E84m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
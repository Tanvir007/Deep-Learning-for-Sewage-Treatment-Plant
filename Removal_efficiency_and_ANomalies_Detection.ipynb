{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oLnm39gH8RlmD5QTaSAqtAIMLohCFnDo",
      "authorship_tag": "ABX9TyPr16M6hp/rcMbb3eYfZxUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanvir007/Deep-Learning-for-Sewage-Treatment-Plant/blob/main/Removal_efficiency_and_ANomalies_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnaN2fkTREtI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from CSV file\n",
        "data = pd.read_csv('/content/drive/MyDrive/BUET Thesis/DSTP - Copy-copy.csv')"
      ],
      "metadata": {
        "id": "_FDE5ma7RJdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gxSdVN_3Ro78",
        "outputId": "62932173-736b-4199-85ee-e2660338c2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date  EfDischargetoGojaria  Reinef  REpH  RECOD  REBOD  REAmmonia  \\\n",
              "0  01-10-2022                257.37    0.01  0.01   0.97   0.98       0.99   \n",
              "1  02-10-2022                265.45    0.00 -0.02   0.99   0.98       0.99   \n",
              "2  03-10-2022                285.96    0.01  0.00   0.99   0.97       0.99   \n",
              "3  04-10-2022                201.39    0.01 -0.01   0.97   0.98       0.99   \n",
              "4  05-10-2022                276.07    0.03  0.02   0.98   0.98       0.99   \n",
              "\n",
              "   RESS  REPhosphate  REFecalColiform  \n",
              "0  0.99         0.63         0.989348  \n",
              "1  1.00         0.52         0.993721  \n",
              "2  0.99         0.50         0.995696  \n",
              "3  0.98         0.49         0.995426  \n",
              "4  0.99         0.59         0.994762  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-978e212d-6446-4206-87ab-ad708163d7e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>EfDischargetoGojaria</th>\n",
              "      <th>Reinef</th>\n",
              "      <th>REpH</th>\n",
              "      <th>RECOD</th>\n",
              "      <th>REBOD</th>\n",
              "      <th>REAmmonia</th>\n",
              "      <th>RESS</th>\n",
              "      <th>REPhosphate</th>\n",
              "      <th>REFecalColiform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01-10-2022</td>\n",
              "      <td>257.37</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.989348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02-10-2022</td>\n",
              "      <td>265.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.993721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>03-10-2022</td>\n",
              "      <td>285.96</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.995696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>04-10-2022</td>\n",
              "      <td>201.39</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.995426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>05-10-2022</td>\n",
              "      <td>276.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.994762</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-978e212d-6446-4206-87ab-ad708163d7e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-978e212d-6446-4206-87ab-ad708163d7e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-978e212d-6446-4206-87ab-ad708163d7e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8b8d2199-c310-41ed-bdd9-aa9c9ee729c7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b8d2199-c310-41ed-bdd9-aa9c9ee729c7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8b8d2199-c310-41ed-bdd9-aa9c9ee729c7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the necessary columns for BOD removal efficiency calculation\n",
        "df = data['Sheet1']\n",
        "\n",
        "# Calculating BOD removal efficiency\n",
        "df['BOD_Removal_Efficiency'] = (df['In-BOD₅\\n(mg/L)'] - df['Ef-BOD₅\\n(mg/L)']) / df['In-BOD₅\\n(mg/L)']\n",
        "\n",
        "# Plotting the removal efficiency over time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(pd.to_datetime(df['date']), df['BOD_Removal_Efficiency'], color='orange', label='BOD Removal Efficiency')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Removal Efficiency')\n",
        "plt.title('Removal Efficiency of BOD Over Time')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6FOZirDjRurJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating COD removal efficiency\n",
        "df['COD_Removal_Efficiency'] = (df['In-CODcr\\n(mg/L)'] - df['Ef-CODcr\\n(mg/L)']) / df['In-CODcr\\n(mg/L)']\n",
        "\n",
        "# Plotting the removal efficiency over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(pd.to_datetime(df['date']), df['COD_Removal_Efficiency'], color='blue', label='COD Removal Efficiency')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Removal Efficiency')\n",
        "plt.title('Removal Efficiency of COD Over Time')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Q1etDf8NzMzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating SS removal efficiency\n",
        "df['SS_Removal_Efficiency'] = (df['In-SS\\n(mg/L)'] - df['Ef-SS\\n(mg/L)']) / df['In-SS\\n(mg/L)']\n",
        "\n",
        "# Plotting the removal efficiency over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(pd.to_datetime(df['date']), df['SS_Removal_Efficiency'], color='green', label='SS Removal Efficiency')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Removal Efficiency')\n",
        "plt.title('Removal Efficiency of SS Over Time')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t9Y0WtvjzSE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# File paths for the uploaded images\n",
        "file_path_bod = \"/mnt/data/Removal Efficiency of BOD Over Time.png\"\n",
        "file_path_cod = \"/mnt/data/Removal Efficiency of COD Over Time.png\"\n",
        "file_path_ss = \"/mnt/data/Removal Efficiency of SS Over Time.png\"\n",
        "\n",
        "# Open the images\n",
        "image_bod = Image.open(file_path_bod)\n",
        "image_cod = Image.open(file_path_cod)\n",
        "image_ss = Image.open(file_path_ss)\n",
        "\n",
        "# Combine the images vertically\n",
        "combined_image = Image.new('RGB', (image_bod.width, image_bod.height + image_cod.height + image_ss.height))\n",
        "combined_image.paste(image_bod, (0, 0))\n",
        "combined_image.paste(image_cod, (0, image_bod.height))\n",
        "combined_image.paste(image_ss, (0, image_bod.height + image_cod.height))\n",
        "\n",
        "# Save and display the combined image\n",
        "combined_image_path = \"/mnt/data/Combined_Removal_Efficiency.png\"\n",
        "combined_image.save(combined_image_path)\n",
        "\n",
        "combined_image.show()\n"
      ],
      "metadata": {
        "id": "CBQ8nFz0zU-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fit Isolation Forest model\n",
        "model = IsolationForest(contamination=0.05, random_state=42)\n",
        "in_cod_data['anomaly'] = model.fit_predict(in_cod_data[['In-COD']])\n",
        "\n",
        "# Mark anomalies\n",
        "in_cod_data['anomaly'] = in_cod_data['anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(in_cod_data.index, in_cod_data['In-COD'], label='In-COD', color='orange')\n",
        "plt.scatter(in_cod_data[in_cod_data['anomaly'] == 1].index,\n",
        "            in_cod_data[in_cod_data['anomaly'] == 1]['In-COD'],\n",
        "            color='red', label='Anomaly', marker='x')\n",
        "plt.title('Anomaly Detection in In-COD Levels (Isolation Forest)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('In-COD (mg/L)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Display the results\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"In-COD Anomaly Detection Results\", dataframe=in_cod_data)\n"
      ],
      "metadata": {
        "id": "o-vpOjTb3J3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of influent parameters to analyze\n",
        "influents = ['In-pH', 'In-CODcr_(mg/L)', 'In-BOD5_(mg/L)', 'In-Ammonia-N_(mg/L)',\n",
        "             'In-SS_(mg/L)', 'In-Phosphate_(mg/L)', 'In-Fecal_Coliform_(mg/L)']\n",
        "\n",
        "# Preparing data for anomaly detection\n",
        "anomaly_results = {}\n",
        "\n",
        "for influent in influents:\n",
        "    # Preparing data\n",
        "    data = df[['date', influent]].copy()\n",
        "    data['date'] = pd.to_datetime(data['date'])\n",
        "    data.set_index('date', inplace=True)\n",
        "    data.rename(columns={influent: 'value'}, inplace=True)\n",
        "\n",
        "    # Apply Isolation Forest\n",
        "    model = IsolationForest(contamination=0.05, random_state=42)\n",
        "    data['anomaly'] = model.fit_predict(data[['value']])\n",
        "    data['anomaly'] = data['anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "    # Save results\n",
        "    anomaly_results[influent] = data\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(data.index, data['value'], label=influent, color='orange')\n",
        "    plt.scatter(data[data['anomaly'] == 1].index,\n",
        "                data[data['anomaly'] == 1]['value'],\n",
        "                color='red', label='Anomaly', marker='x')\n",
        "    plt.title(f'Anomaly Detection in {influent} Levels (Isolation Forest)')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(f'{influent} (Units)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Display results for review\n",
        "for influent, result in anomaly_results.items():\n",
        "    tools.display_dataframe_to_user(name=f\"{influent} Anomaly Detection Results\", dataframe=result)\n"
      ],
      "metadata": {
        "id": "LM1jFnGI3Kul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of effluent parameters to analyze\n",
        "effluents = ['Ef-pH', 'Ef-CODcr_(mg/L)', 'Ef-BOD5_(mg/L)', 'Ef-Ammonia-N_(mg/L)',\n",
        "             'Ef-SS_(mg/L)', 'Ef-Phosphate_(mg/L)', 'Ef-Fecal_Coliform_(mg/L)']\n",
        "\n",
        "# Preparing data for anomaly detection for effluent parameters\n",
        "effluent_anomaly_results = {}\n",
        "\n",
        "for effluent in effluents:\n",
        "    # Preparing data\n",
        "    data = df[['date', effluent]].copy()\n",
        "    data['date'] = pd.to_datetime(data['date'])\n",
        "    data.set_index('date', inplace=True)\n",
        "    data.rename(columns={effluent: 'value'}, inplace=True)\n",
        "\n",
        "    # Apply Isolation Forest\n",
        "    model = IsolationForest(contamination=0.05, random_state=42)\n",
        "    data['anomaly'] = model.fit_predict(data[['value']])\n",
        "    data['anomaly'] = data['anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "    # Save results\n",
        "    effluent_anomaly_results[effluent] = data\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(data.index, data['value'], label=effluent, color='orange')\n",
        "    plt.scatter(data[data['anomaly'] == 1].index,\n",
        "                data[data['anomaly'] == 1]['value'],\n",
        "                color='red', label='Anomaly', marker='x')\n",
        "    plt.title(f'Anomaly Detection in {effluent} Levels (Isolation Forest)')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(f'{effluent} (Units)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Display results for review\n",
        "for effluent, result in effluent_anomaly_results.items():\n",
        "    tools.display_dataframe_to_user(name=f\"{effluent} Anomaly Detection Results\", dataframe=result)\n"
      ],
      "metadata": {
        "id": "EFPKXa1w3URX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to calculate time lags between influent and effluent anomalies\n",
        "def calculate_time_lag(influent_data, effluent_data):\n",
        "    # Filter dates with anomalies\n",
        "    influent_anomalies = influent_data[influent_data['anomaly'] == 1].index\n",
        "    effluent_anomalies = effluent_data[effluent_data['anomaly'] == 1].index\n",
        "\n",
        "    time_lags = []\n",
        "\n",
        "    for eff_date in effluent_anomalies:\n",
        "        # Find the nearest influent anomaly before the effluent anomaly\n",
        "        influent_before = influent_anomalies[influent_anomalies <= eff_date]\n",
        "        if not influent_before.empty:\n",
        "            lag = (eff_date - influent_before[-1]).days\n",
        "            time_lags.append(lag)\n",
        "\n",
        "    return time_lags\n",
        "\n",
        "# Calculate time lags for each influent-effluent pair\n",
        "time_lag_results = {}\n",
        "\n",
        "for influent in influents:\n",
        "    for effluent in effluents:\n",
        "        infl_data = anomaly_results[influent]\n",
        "        effl_data = effluent_anomaly_results[effluent]\n",
        "\n",
        "        # Calculate time lags\n",
        "        lags = calculate_time_lag(infl_data, effl_data)\n",
        "\n",
        "        if lags:\n",
        "            time_lag_results[(influent, effluent)] = lags\n",
        "\n",
        "# Display results\n",
        "time_lag_summary = {f'{infl}_{eff}': lags for (infl, eff), lags in time_lag_results.items()}\n",
        "time_lag_summary\n"
      ],
      "metadata": {
        "id": "BnTZFO7F3Wpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlations between influent and effluent parameters\n",
        "\n",
        "# Create a new DataFrame with influent and effluent parameters aligned\n",
        "merged_data = df.set_index('date')[influents + effluents]\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = merged_data.corr()\n",
        "\n",
        "# Extracting only the correlations between influents and effluents\n",
        "correlations_influent_effluent = correlation_matrix.loc[influents, effluents]\n",
        "\n",
        "# Display the results\n",
        "tools.display_dataframe_to_user(name=\"Correlation between Influent and Effluent Parameters\", dataframe=correlations_influent_effluent)\n"
      ],
      "metadata": {
        "id": "Bm7NG4yT3Y5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the time lag results for visualization\n",
        "time_lag_values = [lag for lags in time_lag_results.values() for lag in lags]\n",
        "\n",
        "# Visualization of time lag distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(time_lag_values, bins=20, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Time Lags between Influent and Effluent Anomalies')\n",
        "plt.xlabel('Time Lag (Days)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZottA_FE3a9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add month information to each anomaly in the time lag data\n",
        "time_lag_with_month = []\n",
        "\n",
        "for (influent, effluent), lags in time_lag_results.items():\n",
        "    for lag in lags:\n",
        "        # Retrieve the effluent dates corresponding to the time lags\n",
        "        effluent_data = effluent_anomaly_results[effluent]\n",
        "        effluent_anomalies = effluent_data[effluent_data['anomaly'] == 1].index\n",
        "\n",
        "        for eff_date in effluent_anomalies:\n",
        "            influent_before = anomaly_results[influent][anomaly_results[influent]['anomaly'] == 1].index\n",
        "            influent_before = influent_before[influent_before <= eff_date]\n",
        "\n",
        "            if not influent_before.empty and (eff_date - influent_before[-1]).days == lag:\n",
        "                time_lag_with_month.append({'influent': influent, 'effluent': effluent, 'lag': lag, 'month': eff_date.month})\n",
        "\n",
        "# Convert to DataFrame\n",
        "time_lag_df = pd.DataFrame(time_lag_with_month)\n",
        "\n",
        "# Group by month to find average lag per month\n",
        "average_lag_per_month = time_lag_df.groupby('month')['lag'].mean().reset_index()\n",
        "\n",
        "# Visualization of average time lag by month\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(average_lag_per_month['month'], average_lag_per_month['lag'], marker='o', color='orange')\n",
        "plt.title('Average Time Lag between Influent and Effluent Anomalies by Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Time Lag (Days)')\n",
        "plt.xticks(ticks=np.arange(1, 13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fTdL_NSB3dta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add month information to the effluent anomaly data for seasonal analysis\n",
        "effluent_data_with_month = effluent_anomaly_results.copy()\n",
        "for effluent, data in effluent_data_with_month.items():\n",
        "    data['month'] = data.index.month\n",
        "\n",
        "# Calculate monthly average for each effluent parameter\n",
        "monthly_average_effluent = {}\n",
        "\n",
        "for effluent, data in effluent_data_with_month.items():\n",
        "    monthly_avg = data.groupby('month')['value'].mean().reset_index()\n",
        "    monthly_average_effluent[effluent] = monthly_avg\n",
        "\n",
        "# Plot seasonal variations for each effluent parameter\n",
        "for effluent, monthly_avg in monthly_average_effluent.items():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(monthly_avg['month'], monthly_avg['value'], marker='o', color='orange')\n",
        "    plt.title(f'Seasonal Variation in {effluent} Levels')\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel(f'{effluent} (Units)')\n",
        "    plt.xticks(ticks=np.arange(1, 13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Iecx3J7x3iKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add month information to the influent anomaly data for seasonal analysis\n",
        "influent_data_with_month = anomaly_results.copy()\n",
        "for influent, data in influent_data_with_month.items():\n",
        "    data['month'] = data.index.month\n",
        "\n",
        "# Calculate monthly average for each influent parameter\n",
        "monthly_average_influent = {}\n",
        "\n",
        "for influent, data in influent_data_with_month.items():\n",
        "    monthly_avg = data.groupby('month')['value'].mean().reset_index()\n",
        "    monthly_average_influent[influent] = monthly_avg\n",
        "\n",
        "# Plot seasonal variations for each influent parameter\n",
        "for influent, monthly_avg in monthly_average_influent.items():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(monthly_avg['month'], monthly_avg['value'], marker='o', color='orange')\n",
        "    plt.title(f'Seasonal Variation in {influent} Levels')\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel(f'{influent} (Units)')\n",
        "    plt.xticks(ticks=np.arange(1, 13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "OLJpfbLr3lzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Preparing data for LOF analysis\n",
        "lof_influents = influent_data_with_month.copy()\n",
        "\n",
        "# Apply LOF to each influent parameter\n",
        "lof_results = {}\n",
        "\n",
        "for influent, data in lof_influents.items():\n",
        "    data = data[['value']].copy()\n",
        "\n",
        "    # Apply LOF\n",
        "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
        "    data['anomaly'] = lof.fit_predict(data)\n",
        "    data['anomaly'] = data['anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "    # Save results\n",
        "    lof_results[influent] = data\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(data.index, data['value'], label=influent, color='orange')\n",
        "    plt.scatter(data[data['anomaly'] == 1].index,\n",
        "                data[data['anomaly'] == 1]['value'],\n",
        "                color='red', label='Anomaly', marker='x')\n",
        "    plt.title(f'Anomaly Detection in {influent} Levels (Local Outlier Factor)')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(f'{influent} (Units)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Display results for review\n",
        "for influent, result in lof_results.items():\n",
        "    tools.display_dataframe_to_user(name=f\"{influent} LOF Anomaly Detection Results\", dataframe=result)\n"
      ],
      "metadata": {
        "id": "QI4Z-Yml3rD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data for LOF analysis for effluent parameters\n",
        "lof_effluents = effluent_data_with_month.copy()\n",
        "\n",
        "# Apply LOF to each effluent parameter\n",
        "lof_effluent_results = {}\n",
        "\n",
        "for effluent, data in lof_effluents.items():\n",
        "    data = data[['value']].copy()\n",
        "\n",
        "    # Apply LOF\n",
        "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
        "    data['anomaly'] = lof.fit_predict(data)\n",
        "    data['anomaly'] = data['anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "    # Save results\n",
        "    lof_effluent_results[effluent] = data\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(data.index, data['value'], label=effluent, color='orange')\n",
        "    plt.scatter(data[data['anomaly'] == 1].index,\n",
        "                data[data['anomaly'] == 1]['value'],\n",
        "                color='red', label='Anomaly', marker='x')\n",
        "    plt.title(f'Anomaly Detection in {effluent} Levels (Local Outlier Factor)')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(f'{effluent} (Units)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Display results for review\n",
        "for effluent, result in lof_effluent_results.items():\n",
        "    tools.display_dataframe_to_user(name=f\"{effluent} LOF Anomaly Detection Results\", dataframe=result)\n"
      ],
      "metadata": {
        "id": "xx_k-Y-t3v9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reusing the previous function to calculate time lags between influent and effluent anomalies for LOF results\n",
        "\n",
        "def calculate_time_lag_lof(influent_data, effluent_data):\n",
        "    # Filter dates with anomalies\n",
        "    influent_anomalies = influent_data[influent_data['anomaly'] == 1].index\n",
        "    effluent_anomalies = effluent_data[effluent_data['anomaly'] == 1].index\n",
        "\n",
        "    time_lags = []\n",
        "\n",
        "    for eff_date in effluent_anomalies:\n",
        "        # Find the nearest influent anomaly before the effluent anomaly\n",
        "        influent_before = influent_anomalies[influent_anomalies <= eff_date]\n",
        "        if not influent_before.empty:\n",
        "            lag = (eff_date - influent_before[-1]).days\n",
        "            time_lags.append(lag)\n",
        "\n",
        "    return time_lags\n",
        "\n",
        "# Calculate time lags for each influent-effluent pair using LOF results\n",
        "time_lag_results_lof = {}\n",
        "\n",
        "for influent in influents:\n",
        "    for effluent in effluents:\n",
        "        infl_data = lof_results[influent]\n",
        "        effl_data = lof_effluent_results[effluent]\n",
        "\n",
        "        # Calculate time lags\n",
        "        lags = calculate_time_lag_lof(infl_data, effl_data)\n",
        "\n",
        "        if lags:\n",
        "            time_lag_results_lof[(influent, effluent)] = lags\n",
        "\n",
        "# Display results\n",
        "time_lag_summary_lof = {f'{infl}_{eff}': lags for (infl, eff), lags in time_lag_results_lof.items()}\n",
        "time_lag_summary_lof\n"
      ],
      "metadata": {
        "id": "zetZXC_Z3yaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlations between influent and effluent parameters using LOF results\n",
        "\n",
        "# Create a new DataFrame with influent and effluent parameters aligned using LOF anomaly results\n",
        "merged_lof_data = pd.DataFrame(index=df['date'])\n",
        "\n",
        "# Add influent parameters to the merged DataFrame\n",
        "for influent, data in lof_results.items():\n",
        "    merged_lof_data[influent] = data['value'].reindex(merged_lof_data.index)\n",
        "\n",
        "# Add effluent parameters to the merged DataFrame\n",
        "for effluent, data in lof_effluent_results.items():\n",
        "    merged_lof_data[effluent] = data['value'].reindex(merged_lof_data.index)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix_lof = merged_lof_data.corr()\n",
        "\n",
        "# Extracting only the correlations between influents and effluents\n",
        "correlations_influent_effluent_lof = correlation_matrix_lof.loc[influents, effluents]\n",
        "\n",
        "# Display the results\n",
        "tools.display_dataframe_to_user(name=\"LOF Correlation between Influent and Effluent Parameters\", dataframe=correlations_influent_effluent_lof)\n"
      ],
      "metadata": {
        "id": "7KMx14Jt30ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add month information to each anomaly in the time lag data for LOF results\n",
        "time_lag_with_month_lof = []\n",
        "\n",
        "for (influent, effluent), lags in time_lag_results_lof.items():\n",
        "    for lag in lags:\n",
        "        # Retrieve the effluent dates corresponding to the time lags\n",
        "        effluent_data = lof_effluent_results[effluent]\n",
        "        effluent_anomalies = effluent_data[effluent_data['anomaly'] == 1].index\n",
        "\n",
        "        for eff_date in effluent_anomalies:\n",
        "            influent_before = lof_results[influent][lof_results[influent]['anomaly'] == 1].index\n",
        "            influent_before = influent_before[influent_before <= eff_date]\n",
        "\n",
        "            if not influent_before.empty and (eff_date - influent_before[-1]).days == lag:\n",
        "                time_lag_with_month_lof.append({'influent': influent, 'effluent': effluent, 'lag': lag, 'month': eff_date.month})\n",
        "\n",
        "# Convert to DataFrame\n",
        "time_lag_df_lof = pd.DataFrame(time_lag_with_month_lof)\n",
        "\n",
        "# Group by month to find average lag per month\n",
        "average_lag_per_month_lof = time_lag_df_lof.groupby('month')['lag'].mean().reset_index()\n",
        "\n",
        "# Visualization of average time lag by month\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(average_lag_per_month_lof['month'], average_lag_per_month_lof['lag'], marker='o', color='orange')\n",
        "plt.title('Average Time Lag between Influent and Effluent Anomalies by Month (LOF)')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Time Lag (Days)')\n",
        "plt.xticks(ticks=np.arange(1, 13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "afFI0rkn32oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add month information to the effluent LOF anomaly data for seasonal analysis\n",
        "for effluent, data in lof_effluent_results.items():\n",
        "    data['month'] = data.index.month\n",
        "\n",
        "# Calculate monthly average for each effluent parameter\n",
        "monthly_average_effluent_lof = {}\n",
        "\n",
        "for effluent, data in lof_effluent_results.items():\n",
        "    monthly_avg = data.groupby('month')['value'].mean().reset_index()\n",
        "    monthly_average_effluent_lof[effluent] = monthly_avg\n",
        "\n",
        "# Plot seasonal variations for each effluent parameter using LOF results\n",
        "for effluent, monthly_avg in monthly_average_effluent_lof.items():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(monthly_avg['month'], monthly_avg['value'], marker='o', color='orange')\n",
        "    plt.title(f'Seasonal Variation in {effluent} Levels (LOF)')\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel(f'{effluent} (Units)')\n",
        "    plt.xticks(ticks=np.arange(1, 13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "vYOlRiqK36OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add month information to the influent LOF anomaly data for seasonal analysis\n",
        "for influent, data in lof_results.items():\n",
        "    data['month'] = data.index.month\n",
        "\n",
        "# Calculate monthly average for each influent parameter\n",
        "monthly_average_influent_lof = {}\n",
        "\n",
        "for influent, data in lof_results.items():\n",
        "    monthly_avg = data.groupby('month')['value'].mean().reset_index()\n",
        "    monthly_average_influent_lof[influent] = monthly_avg\n",
        "\n",
        "# Plot seasonal variations for each influent parameter using LOF results\n",
        "for influent, monthly_avg in monthly_average_influent_lof.items():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(monthly_avg['month'], monthly_avg['value'], marker='o', color='orange')\n",
        "    plt.title(f'Seasonal Variation in {influent} Levels (LOF)')\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel(f'{influent} (Units)')\n",
        "    plt.xticks(ticks=np.arange(1, 13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "MtzOq4X339Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "# Preparing data for OCSVM analysis\n",
        "ocsvm_influents = influent_data_with_month.copy()\n",
        "\n",
        "# Apply OCSVM to each influent parameter\n",
        "ocsvm_results = {}\n",
        "\n",
        "for influent, data in ocsvm_influents.items():\n",
        "    data = data[['value']].copy()\n",
        "\n",
        "    # Apply OCSVM\n",
        "    ocsvm = OneClassSVM(nu=0.05, kernel='rbf', gamma='scale')\n",
        "    data['anomaly'] = ocsvm.fit_predict(data)\n",
        "    data['anomaly'] = data['anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "    # Save results\n",
        "    ocsvm_results[influent] = data\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(data.index, data['value'], label=influent, color='orange')\n",
        "    plt.scatter(data[data['anomaly'] == 1].index,\n",
        "                data[data['anomaly'] == 1]['value'],\n",
        "                color='red', label='Anomaly', marker='x')\n",
        "    plt.title(f'Anomaly Detection in {influent} Levels (OCSVM)')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(f'{influent} (Units)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Display results for review\n",
        "for influent, result in ocsvm_results.items():\n",
        "    tools.display_dataframe_to_user(name=f\"{influent} OCSVM Anomaly Detection Results\", dataframe=result)\n"
      ],
      "metadata": {
        "id": "nU8k5yE-4Bng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data for OCSVM analysis for effluent parameters\n",
        "ocsvm_effluents = effluent_data_with_month.copy()\n",
        "\n",
        "# Apply OCSVM to each effluent parameter\n",
        "ocsvm_effluent_results = {}\n",
        "\n",
        "for effluent, data in ocsvm_effluents.items():\n",
        "    data = data[['value']].copy()\n",
        "\n",
        "    # Apply OCSVM\n",
        "    ocsvm = OneClassSVM(nu=0.05, kernel='rbf', gamma='scale')\n",
        "    data['anomaly'] = ocsvm.fit_predict(data)\n",
        "    data['anomaly'] = data['anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "    # Save results\n",
        "    ocsvm_effluent_results[effluent] = data\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(data.index, data['value'], label=effluent, color='orange')\n",
        "    plt.scatter(data[data['anomaly'] == 1].index,\n",
        "                data[data['anomaly'] == 1]['value'],\n",
        "                color='red', label='Anomaly', marker='x')\n",
        "    plt.title(f'Anomaly Detection in {effluent} Levels (OCSVM)')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(f'{effluent} (Units)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Display results for review\n",
        "for effluent, result in ocsvm_effluent_results.items():\n",
        "    tools.display_dataframe_to_user(name=f\"{effluent} OCSVM Anomaly Detection Results\", dataframe=result)\n"
      ],
      "metadata": {
        "id": "U3H2_Z4Q4FdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reusing the previous function to calculate time lags between influent and effluent anomalies for OCSVM results\n",
        "\n",
        "def calculate_time_lag_ocsvm(influent_data, effluent_data):\n",
        "    # Filter dates with anomalies\n",
        "    influent_anomalies = influent_data[influent_data['anomaly'] == 1].index\n",
        "    effluent_anomalies = effluent_data[effluent_data['anomaly'] == 1].index\n",
        "\n",
        "    time_lags = []\n",
        "\n",
        "    for eff_date in effluent_anomalies:\n",
        "        # Find the nearest influent anomaly before the effluent anomaly\n",
        "        influent_before = influent_anomalies[influent_anomalies <= eff_date]\n",
        "        if not influent_before.empty:\n",
        "            lag = (eff_date - influent_before[-1]).days\n",
        "            time_lags.append(lag)\n",
        "\n",
        "    return time_lags\n",
        "\n",
        "# Calculate time lags for each influent-effluent pair using OCSVM results\n",
        "time_lag_results_ocsvm = {}\n",
        "\n",
        "for influent in influents:\n",
        "    for effluent in effluents:\n",
        "        infl_data = ocsvm_results[influent]\n",
        "        effl_data = ocsvm_effluent_results[effluent]\n",
        "\n",
        "        # Calculate time lags\n",
        "        lags = calculate_time_lag_ocsvm(infl_data, effl_data)\n",
        "\n",
        "        if lags:\n",
        "            time_lag_results_ocsvm[(influent, effluent)] = lags\n",
        "\n",
        "# Display results\n",
        "time_lag_summary_ocsvm = {f'{infl}_{eff}': lags for (infl, eff), lags in time_lag_results_ocsvm.items()}\n",
        "time_lag_summary_ocsvm\n"
      ],
      "metadata": {
        "id": "bd0gIMlJ4Hk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlations between influent and effluent parameters using OCSVM results\n",
        "\n",
        "# Create a new DataFrame with influent and effluent parameters aligned using OCSVM anomaly results\n",
        "merged_ocsvm_data = pd.DataFrame(index=df['date'])\n",
        "\n",
        "# Add influent parameters to the merged DataFrame\n",
        "for influent, data in ocsvm_results.items():\n",
        "    merged_ocsvm_data[influent] = data['value'].reindex(merged_ocsvm_data.index)\n",
        "\n",
        "# Add effluent parameters to the merged DataFrame\n",
        "for effluent, data in ocsvm_effluent_results.items():\n",
        "    merged_ocsvm_data[effluent] = data['value'].reindex(merged_ocsvm_data.index)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix_ocsvm = merged_ocsvm_data.corr()\n",
        "\n",
        "# Extracting only the correlations between influents and effluents\n",
        "correlations_influent_effluent_ocsvm = correlation_matrix_ocsvm.loc[influents, effluents]\n",
        "\n",
        "# Display the results\n",
        "tools.display_dataframe_to_user(name=\"OCSVM Correlation between Influent and Effluent Parameters\", dataframe=correlations_influent_effluent_ocsvm)\n"
      ],
      "metadata": {
        "id": "tjLNyKWo4JyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the time lag results for visualization using OCSVM results\n",
        "time_lag_values_ocsvm = [lag for lags in time_lag_results_ocsvm.values() for lag in lags]\n",
        "\n",
        "# Visualization of time lag distribution using OCSVM results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(time_lag_values_ocsvm, bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Time Lags between Influent and Effluent Anomalies (OCSVM)')\n",
        "plt.xlabel('Time Lag (Days)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CF0qI3yb4L5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add month information to each anomaly in the time lag data for OCSVM results\n",
        "time_lag_with_month_ocsvm = []\n",
        "\n",
        "for (influent, effluent), lags in time_lag_results_ocsvm.items():\n",
        "    for lag in lags:\n",
        "        # Retrieve the effluent dates corresponding to the time lags\n",
        "        effluent_data = ocsvm_effluent_results[effluent]\n",
        "        effluent_anomalies = effluent_data[effluent_data['anomaly'] == 1].index\n",
        "\n",
        "        for eff_date in effluent_anomalies:\n",
        "            influent_before = ocsvm_results[influent][ocsvm_results[influent]['anomaly'] == 1].index\n",
        "            influent_before = influent_before[influent_before <= eff_date]\n",
        "\n",
        "            if not influent_before.empty and (eff_date - influent_before[-1]).days == lag:\n",
        "                time_lag_with_month_ocsvm.append({'influent': influent, 'effluent': effluent, 'lag': lag, 'month': eff_date.month})\n",
        "\n",
        "# Convert to DataFrame\n",
        "time_lag_df_ocsvm = pd.DataFrame(time_lag_with_month_ocsvm)\n",
        "\n",
        "# Group by month to find average lag per month\n",
        "average_lag_per_month_ocsvm = time_lag_df_ocsvm.groupby('month')['lag'].mean().reset_index()\n",
        "\n",
        "# Visualization of average time lag by month\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(average_lag_per_month_ocsvm['month'], average_lag_per_month_ocsvm['lag'], marker='o', color='orange')\n",
        "plt.title('Average Time Lag between Influent and Effluent Anomalies by Month (OCSVM)')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Time Lag (Days)')\n",
        "plt.xticks(ticks=np.arange(1, 13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Pww2O0Yv4OIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimize by pre-computing anomaly dates\n",
        "# Create dictionaries for quicker lookups\n",
        "influent_anomaly_dates = {influent: ocsvm_results[influent][ocsvm_results[influent]['anomaly'] == 1].index for influent in ocsvm_results}\n",
        "effluent_anomaly_dates = {effluent: ocsvm_effluent_results[effluent][ocsvm_effluent_results[effluent]['anomaly'] == 1].index for effluent in ocsvm_effluent_results}\n",
        "\n",
        "# Re-calculate time lags with optimization\n",
        "optimized_time_lag_with_month_ocsvm = []\n",
        "\n",
        "for (influent, effluent), lags in time_lag_results_ocsvm.items():\n",
        "    for lag in lags:\n",
        "        # Iterate through effluent anomalies\n",
        "        for eff_date in effluent_anomaly_dates[effluent]:\n",
        "            influent_before = influent_anomaly_dates[influent][influent_anomaly_dates[influent] <= eff_date]\n",
        "\n",
        "            if not influent_before.empty and (eff_date - influent_before[-1]).days == lag:\n",
        "                optimized_time_lag_with_month_ocsvm.append({'influent': influent, 'effluent': effluent, 'lag': lag, 'month': eff_date.month})\n",
        "\n",
        "# Convert to DataFrame\n",
        "optimized_time_lag_df_ocsvm = pd.DataFrame(optimized_time_lag_with_month_ocsvm)\n",
        "\n",
        "# Group by month to find average lag per month\n",
        "optimized_average_lag_per_month_ocsvm = optimized_time_lag_df_ocsvm.groupby('month')['lag'].mean().reset_index()\n",
        "\n",
        "# Visualization of average time lag by month\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(optimized_average_lag_per_month_ocsvm['month'], optimized_average_lag_per_month_ocsvm['lag'], marker='o', color='orange')\n",
        "plt.title('Average Time Lag between Influent and Effluent Anomalies by Month (OCSVM)')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Time Lag (Days)')\n",
        "plt.xticks(ticks=np.arange(1, 13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LaeVq_q74Qiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add month information to the effluent OCSVM anomaly data for seasonal analysis\n",
        "for effluent, data in ocsvm_effluent_results.items():\n",
        "    data['month'] = data.index.month\n",
        "\n",
        "# Calculate monthly average for each effluent parameter\n",
        "monthly_average_effluent_ocsvm = {}\n",
        "\n",
        "for effluent, data in ocsvm_effluent_results.items():\n",
        "    monthly_avg = data.groupby('month')['value'].mean().reset_index()\n",
        "    monthly_average_effluent_ocsvm[effluent] = monthly_avg\n",
        "\n",
        "# Plot seasonal variations for each effluent parameter using OCSVM results\n",
        "for effluent, monthly_avg in monthly_average_effluent_ocsvm.items():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(monthly_avg['month'], monthly_avg['value'], marker='o', color='orange')\n",
        "    plt.title(f'Seasonal Variation in {effluent} Levels (OCSVM)')\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel(f'{effluent} (Units)')\n",
        "    plt.xticks(ticks=np.arange(1, 13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Q-8c1aIc4Tmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add month information to the influent OCSVM anomaly data for seasonal analysis\n",
        "for influent, data in ocsvm_results.items():\n",
        "    data['month'] = data.index.month\n",
        "\n",
        "# Calculate monthly average for each influent parameter\n",
        "monthly_average_influent_ocsvm = {}\n",
        "\n",
        "for influent, data in ocsvm_results.items():\n",
        "    monthly_avg = data.groupby('month')['value'].mean().reset_index()\n",
        "    monthly_average_influent_ocsvm[influent] = monthly_avg\n",
        "\n",
        "# Plot seasonal variations for each influent parameter using OCSVM results\n",
        "for influent, monthly_avg in monthly_average_influent_ocsvm.items():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(monthly_avg['month'], monthly_avg['value'], marker='o', color='orange')\n",
        "    plt.title(f'Seasonal Variation in {influent} Levels (OCSVM)')\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel(f'{influent} (Units)')\n",
        "    plt.xticks(ticks=np.arange(1, 13), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "gs5Z0MJM4Wfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the time lag results for visualization using LOF results\n",
        "time_lag_values_lof = [lag for lags in time_lag_results_lof.values() for lag in lags]\n",
        "\n",
        "# Visualization of time lag distribution using LOF results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(time_lag_values_lof, bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Time Lags between Influent and Effluent Anomalies (LOF)')\n",
        "plt.xlabel('Time Lag (Days)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Avzz9cHH4YfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining anomaly results from all three models: Isolation Forest, LOF, and OCSVM\n",
        "\n",
        "# Function to combine results from all models\n",
        "def combine_anomaly_results(df, isolation_forest_results, lof_results, ocsvm_results):\n",
        "    combined_df = df.copy()\n",
        "    combined_df['Isolation_Forest'] = isolation_forest_results['anomaly'].reindex(df.index, fill_value=0)\n",
        "    combined_df['LOF'] = lof_results['anomaly'].reindex(df.index, fill_value=0)\n",
        "    combined_df['OCSVM'] = ocsvm_results['anomaly'].reindex(df.index, fill_value=0)\n",
        "    combined_df['Combined_Anomaly'] = (combined_df['Isolation_Forest'] +\n",
        "                                       combined_df['LOF'] +\n",
        "                                       combined_df['OCSVM'])\n",
        "    combined_df['Anomaly_Flag'] = combined_df['Combined_Anomaly'] >= 2  # Anomaly if detected by at least 2 models\n",
        "    return combined_df\n",
        "\n",
        "# Apply the function for influent parameters\n",
        "combined_results_influent = {}\n",
        "for influent in influents:\n",
        "    combined_results_influent[influent] = combine_anomaly_results(df.set_index('date')[[influent]],\n",
        "                                                                  anomaly_results[influent],\n",
        "                                                                  lof_results[influent],\n",
        "                                                                  ocsvm_results[influent])\n",
        "\n",
        "# Apply the function for effluent parameters\n",
        "combined_results_effluent = {}\n",
        "for effluent in effluents:\n",
        "    combined_results_effluent[effluent] = combine_anomaly_results(df.set_index('date')[[effluent]],\n",
        "                                                                  effluent_anomaly_results[effluent],\n",
        "                                                                  lof_effluent_results[effluent],\n",
        "                                                                  ocsvm_effluent_results[effluent])\n",
        "\n",
        "# Display combined results for influent parameters\n",
        "for influent, result in combined_results_influent.items():\n",
        "    tools.display_dataframe_to_user(name=f\"{influent} Combined Anomaly Detection Results\", dataframe=result)\n",
        "\n",
        "# Display combined results for effluent parameters\n",
        "for effluent, result in combined_results_effluent.items():\n",
        "    tools.display_dataframe_to_user(name=f\"{effluent} Combined Anomaly Detection Results\", dataframe=result)\n",
        "\n"
      ],
      "metadata": {
        "id": "xtZ_EW0F4d1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating anomaly frequencies for each influent and effluent parameter\n",
        "\n",
        "# Function to calculate anomaly frequencies\n",
        "def calculate_anomaly_frequency(combined_results):\n",
        "    anomaly_frequencies = {}\n",
        "    for parameter, result in combined_results.items():\n",
        "        frequency = result['Anomaly_Flag'].sum()\n",
        "        anomaly_frequencies[parameter] = frequency\n",
        "    return anomaly_frequencies\n",
        "\n",
        "# Calculate anomaly frequencies for influent and effluent parameters\n",
        "anomaly_frequency_influent = calculate_anomaly_frequency(combined_results_influent)\n",
        "anomaly_frequency_effluent = calculate_anomaly_frequency(combined_results_effluent)\n",
        "\n",
        "# Convert to DataFrame for easier plotting\n",
        "anomaly_frequency_df = pd.DataFrame({\n",
        "    'Parameter': list(anomaly_frequency_influent.keys()) + list(anomaly_frequency_effluent.keys()),\n",
        "    'Frequency': list(anomaly_frequency_influent.values()) + list(anomaly_frequency_effluent.values()),\n",
        "    'Type': ['Influent'] * len(anomaly_frequency_influent) + ['Effluent'] * len(anomaly_frequency_effluent)\n",
        "})\n",
        "\n",
        "# Plotting anomaly frequencies\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.bar(anomaly_frequency_df['Parameter'], anomaly_frequency_df['Frequency'], color='skyblue')\n",
        "plt.title('Anomaly Frequencies Across All Models (Isolation Forest, LOF, OCSVM)')\n",
        "plt.xlabel('Parameter')\n",
        "plt.ylabel('Anomaly Frequency')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G2tSl6OD4gTE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}